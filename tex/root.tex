%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
\usepackage{mathrsfs}
\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{hyperref}
\usepackage{caption}
\captionsetup[table]{position=bottom}   %% or below
\usepackage{cite}

\title{\LARGE \bf
Extended Dynamic Mode Decomposition with Jacobian Residual-Penalization for Learning Bilinear, Control-affine Koopman Models
}

\author{Jeong Hun Lee$^{1}$ % <-this % stops a space
}

\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Data-driven, Koopman-based learning methods offer a practical and more efficient technique to control nonlinear dynamical systems by lifting the dynamics into a linear space of observable functions. However, many Koopman learning frameworks specifically learn \emph{lifted linear} models, which assume linearity with respect to the controls, without also incorporating any \emph{derivative} information of the system. This paper presents an extension of the commonly-used Extended Dynamic Mode Decomposition (EDMD) method for learning a \emph{lifted bilinear}, control-affine system while also penalizing residuals of the \emph{Jacobians} in addition to the states. The learned, bilinear model is controlled using an LQR controller, where the learned Jacobians can be exploited in the feedback policy. This benefit of penalizing the jacobian residual is highlighted in the example of a simulated cartpole, for which LQR can successfully stabilize about a fixed point and track a swing-up trajectory.

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

Linear systems benefit from a great amount of efficient algorithms for practical, online control. However, many real-world problems are modeled as nonlinear systems (e.g. fluid dynamics, double pendulum, etc.) but suffer from the lack of a general framework and efficient algorithms for efficient, real-time control tasks. Therefore, it is common to linearize the nonlinear system about a fixed point for stabilization tasks or a reference trajectory for tracking. However, these linearizations are local and do not model the entire space of the dynamical system.

The Koopman Operator offers a technique to capture the global behavior of a nonlinear dynamical system by "lifting" the system into an infinite space of scalar-valued functions of the states \cite{1}. This function space is canonically known as the Hilbert space and the functions are known as \emph{observables}. This Koopman representation of the dynamics suggests that any nonlinear function can be represented by an infinite linear combination of observables. However, an infinite dimensional space is impractical, so in application, the goal becomes to find an appropriate, finite basis of observable functions. In the Koopman Canonical Transform (KCT), the goal is specifically to find enough observables whose linear combination can also be used to approximately represent the state \cite{2}. These observables are also known as \emph{eigenfunctions}. Commonly, choosing appropriate eigenfunctions stems from engineering intuition and system knowledge, but recent works have also aimed to use data-driven methods \cite{3}.

For identifying Koopman models, data-driven methods have gained popularity. Specifically, Dynamic Mode Decomposition (DMD) and Extended Dynamic Mode Decomposition (EDMD) have been widely used to identify best-fit, approximate, linear Koopman models for various nonlinear, robotic systems \cite{4, 5, 6, 7, 8}. Both methods involve solving a linear, least squares (LLS) regression over the lifted data (corresponding eigenfunction values) to generate a best-fit, approximate Koopman representation of the original dynamics. While these lifted, linear models pair well with existing, efficient algorithms, there is no guaranteed that these Koopman models are valid global representations of the system. This is due to linear Koopman approximations inherently assuming that the model is linear with respect to the control inputs in the Hilbert space, which further restricts the subspace in which the linear model is learned \cite{9}. Recently, small attention has been given to use EDMD to identify bilinear, control-affine Koopman models for nonlinear MPC with improved performance over their linear counterparts \cite{10, 11}. These bilinear representations aim to preserve some of the structure and computational efficiency of linear systems while incorporating nonlinearity with respect to the control inputs.

While works have improved on lifted, linear models by learning lifted, bilinear representations, little consideration has also been given to regularizing techniques in EDMD. When learning the Koopman model, Lasso (L1) regularization is commonly implemented to promote sparsity in the regression, and the widely-known SINDYc algorithm implements the more computationally-efficient, sequential thresholded least-squares method \cite{12}. However, these implementations only look to penalize the residual of the states, when the derivative information of the system can also be used to improve the lifted model. Towards this goal, this paper presents a new EDMD framework that also penalizes the jacobian residual in addition to the state residuals in the LLS regression when learning the lifted, bilinear Koopman model. First, preliminary/background information on the Koopman operator, the Koopman Canonical Transform, and EDMD will be provided in Section II. Next, the EDMD framework with the incorporated jacobian residual-penalization will be presenting in Section III. Finally, the resulting Koopman model will be demonstrated on a simulated cartpole with an LQR controller in Section IV before we conclude in Section V.

\section{Preliminaries/Background}

\subsection{The Koopman Operator}

Before introducing the Koopman operator, we introduce the continuous nonlinear, time-dynamical system without controls:
$$
\Dot{x} = f(x) \eqno{(1)}
$$
with state $x \in \mathcal{X} \subseteq R^{d}$ and $f$ being lipschitz continuous on $\mathcal{X}$. The flow map of this dynamical system is denoted as $F_{t}(x)$ where $\frac{d}{dt}F_{t}(x) = f(F_{t}(x))$. In discrete time, the dynamical system becomes:
$$
\Dot{x}_{k+1} = F_{t}(x_{k}) \eqno{(2)}
$$

The Koopman operator of this dynamical system is defined as:

$$
K_{t}{\psi} = \psi \circ F_{t} \eqno{(3)}
$$
for all $\psi \in \mathcal{C(X)}$, where $\mathcal{C(X)}$ represents the infinite dimensional Hilbert space of continuous functions. We refer to these functions $\psi$ as \emph{observables} that "lift" the function into the Hilbert space. The operator $\circ$ denotes the composition operator ($g \circ f = g(f(x))$). The Koopman operator suggests that the continuous, nonlinear dynamical system in $\mathcal{X}$ can be globally represented by an infinite dimensional, linear system in $\mathcal{C(X)}$. If we look at the Koopman operator in discrete time,
$$
K_{t}{\psi(x_{k})} = \psi(x_{k+1}) \eqno{(4)}
$$
this more clearly suggests that we can represent the nonlinear dynamics as a linear system in $\mathcal{C(X)}$ in discrete time as well.

\subsection{The Koopman Canonical Transform}

Before introducing the Koopman Canonical Transform (KCT), we first introduce the \emph{eigenfunctions} $\phi \in \mathcal{C(X)}$. These are specific types of observables that evolve linearly with $F_{t}$:
$$
K_{t}\phi(x) = e^{\lambda t}\phi(x) \eqno{(5)}
$$
where $\lambda \in \mathbb{C}$ are the \emph{eigenvalues} corresponding to $\phi(x)$.

Instead of creating a lifted, linear representation, the KCT specifically incorporates the control inputs in the dynamics $\Dot{x} = f(x, u)$ and transforms the dynamics into a lifted, bilinear form where the observables $\psi(x)$ are the eigenfunctions $\phi(x)$ of the Koopman operator \cite{2}. This assumes that the state itself can be represented by a finite, linear combination of the eigenfunctions:
$$
x = \sum_{i=1}^{n} v_{i}\phi_{i}(x) \; \forall \; x \in \mathcal{X} \eqno{(6)}
$$
where $v_{i} \in \mathbb{C}^{d}$. Using these eigenfunctions $\phi_{i}(x)$ as nonlinear basis in $\mathcal{C(X)}$ suggests a transformation from $\mathcal{X}$ to $C(X)$:
$$
x = gz \eqno{(7)}
$$
where $z = \phi(x) = [\phi_{1}(x) \; \phi_{2}(x) \; ... \; \phi_{n}(x)]^{T}$ and $g = [v_{1} \; v_{2} \; ... \; v_{n}]$. The lifted, bilinear Koopman model from the KCT is defined as:
$$
\Dot{z} = A^{z}z + \sum_{i=1}^{m} u_{i}C_{i}z \eqno{(8)}
$$
where $z \in \mathbb{R}^{n}, n < \infty$. In discrete time, the bilinear Koopman model becomes:
$$
x_{k} = gz_{k} \eqno{(9)} \\
$$
$$
z_{k+1} = A^{z}z_{k} + \sum_{i=1}^{m} u_{k,i}C_{i}z_{k} \eqno{(10)}
$$

\subsection{Extended Dynamic Mode Decomposition}

To learn an approximate, lifted bilinear model as suggested by the KCT, Extended Dynamic Mode Decomposition (EDMD) is used. This is a data-driven method that takes data (i.e. time history of the state) and splits it into 2 datasets:
$$
\mathbf{X} = [x_{1} \; x_{2} \; ... \; x_{N-1}] \qquad \mathbf{X}' = [x_{2} \; x_{3} \; ... \; x_{N}] \eqno{(12)} \\
$$
The data is then lifted into the Hilbert space with a chosen set of eigenfunctions $\phi(x)$, which is based on system knowledge, engineering intuition, and/or data-driven methods \cite{3}:
$$
\mathbf{Z} = [\phi(x_{1}) \; \phi(x_{2}) \; ... \; \phi(x_{N-1})] = [z_{1} \; z_{2} \; ... \; z_{N-1}]
$$
$$
\mathbf{Z}' = [\phi(x_{2}) \; \phi(x_{3}) \; ... \; \phi(x_{N})] = [z_{2} \; z_{3} \; ... \; z_{N}] \eqno{(13)} \\
$$
In order to properly learn a bilinear representation, specifically the bilinear coefficients, the control inputs must also be incorporated in the lifted data:
$$
\mathbf{Z_{u}} = \begin{bmatrix}
z_{1} & z_{2} & ... & z_{N-1} \\
z_{1}u_{1} & z_{2}u_{1} & ... & z_{N-1}u_{1} \\
z_{1}u_{2} & z_{2}u_{2} & ... & z_{N-1}u_{2} \\
... & ... & ... & ... \\
z_{1}u_{m} & z_{2}u_{m} & ... & z_{N-1}u_{m} \\
\end{bmatrix} \eqno{(14)}
$$
Learning both the bilinear Koopman model and the $\mathcal{X}$-to-$\mathcal{C(X)}$ transformation can then be formulated as a linear least-squares (LLS) regression problem:
$$
\min_{E} ||Z' - EZ_{u}||^{2} \eqno{(15)}
$$
$$
\min_{g} ||X - gZ||^{2} \eqno{(16)}
$$
where $E = [A^{z} \; C_{1} \; C_{2} \; ... \; C_{m}]$. To prevent overfitting, Lasso ($l_{1}$) regularization is used to promote sparsity in addition to other methods, such as the sequential thresholded least-squares method as seen in SINDYc \cite{12}. One thing to note is that due to EDMD learning over a discrete time history, EDMD learns a discrete bilinear model.

\section{EDMD with Jacobian Residual-Penalization}

As seen in (15), the LLS optimization problem only minimizes the sum-of-squares of the eigenfunction residuals, which are functions of the state. As a consequence, the dynamics jacobians are not taken into account in the learning problem; more specifically, the residuals of the dynamics jacobians themselves are not penalized, even though the goal of EDMD is to learn these jacobian matrices. Therefore, incorporating the jacobian residuals may lead to a more accurate bilinear Koopman representation of the nonlinear dynamics.

To formulate the jacobian residuals for the LLS regression of the EDMD, a time history of the dynamics jacobians must also be recorded as part of the data:
$$
\mathbf{A^{x}} = [A^{x}_{1} \; A^{x}_{2} \; ... \; A^{x}_{N-1}] \qquad \mathbf{B^{x}} = [B^{x}_{1} \; B^{x}_{2} \; ... \; B^{x}_{N-1}] \eqno{(17)} \\
$$
In addition, the jacobians of the bilinear Koopman model with respect to the original states $x$ and controls $u$ can be determined as:
$$
\frac{\partial Z_{k+1}}{x_{k}} = (A^{z} + \sum_{i=1}^{m} u_{k,i}C_{i})\frac{\partial z_{k}}{\partial x_{k}} = E\hat{A}
$$
$$
\frac{\partial Z_{k+1}}{u_{k}} = B^{z} + [C_{1}z_{k} \; C_{2}z_{k} \; ... \; C_{m}z_{k}] = E\hat{B} \eqno{(18)} 
$$
where:
$$
\hat{A}_{k} = \begin{bmatrix} \frac{\partial z_{k}}{\partial x_{k}} \\ 0 \\ u_{k,1}\frac{\partial z_{k}}{\partial x_{k}} \\ u_{k,2}\frac{\partial z_{k}}{\partial x_{k}} \\ ... \\ u_{k, m}\frac{\partial z_{k}}{\partial x_{k}} \end{bmatrix} \qquad \hat{B}_{k} = \begin{bmatrix} 0 \\ I \\ [x_{k} \; 0 \; ... \; 0] \\ [0 \; x_{k} \; ... \; 0] \\ ... \\ [0 \; 0 \; ... \; x_{k}] \end{bmatrix} \eqno{(19)}
$$

The EDMD with the jacobian residual-penalization can then be written as:
$$
\min_{E} (1-\alpha)||Z' - EZ_{u}||^{2} + \alpha||A^{x} - gE\hat{A}||^{2} + \alpha||B^{x} - gE\hat{B}||^{2} \eqno{(20)}
$$
where $Z_{u}$ has been slightly changed to take into account a linear term for $u$:
$$
\mathbf{Z_{u}} = \begin{bmatrix}
z_{1} & z_{2} & ... & z_{N-1} \\
u_{1} & u_{2} & ... & u_{N-1} \\
z_{1}u_{1} & z_{2}u_{1} & ... & z_{N-1}u_{1} \\
z_{1}u_{2} & z_{2}u_{2} & ... & z_{N-1}u_{2} \\
... & ... & ... & ... \\
z_{1}u_{m} & z_{2}u_{m} & ... & z_{N-1}u_{m} \\
\end{bmatrix} \eqno{(21)}
$$

\section{Simulated Cartpole Learning and Control}

\subsection{Nominal System Details}

A Cartpole model was chosen with the following nonlinear dynamics:

$$
\begin{bmatrix} \Dot{v} \\ \Dot{\omega} \end{bmatrix} = -\begin{bmatrix}
m_{c} + m_{p} & m_{p}lcos(\theta) \\
m_{p}lcos(\theta) & m_{p}l^{2} \end{bmatrix}^{-1}
$$
$$\bigg(\begin{bmatrix}
0 & -m_{p}\omega lcos(\theta) \\
0 & 0 \end{bmatrix} \begin{bmatrix}
v \\ \omega \end{bmatrix} + \begin{bmatrix}
0 \\
m_{p}glsin(\theta)\\
\end{bmatrix} - \begin{bmatrix} 1 \\ 0 \end{bmatrix}u\bigg) \eqno{(22)}
$$
with states $x = [y, \theta, v, \omega]^{T}$, where $y, \theta$ describe the position of the cartpole and angle of the pendulum respectively and $v, \omega$ describe the respective velocities. $m_{c}, m_{p}$ describe the masses of the cartpole and pendulum respectively with $l$ describing the length of the pendulum. $g$ denotes the gravitational constant.

To compare our bilinear EDMD with the jacobian residual-penalization to the nominal bilinear EDMD framework, LQR controllers were designed for each EDMD-generated model for 2 tasks: 1) stabilize the cartpole at $[0, \pi]$ using time-invarient LQR 2) track a swing-up reference trajectory using tim-varying LQR (TVLQR). The respective code for each task can be found on GitHub at \url{https://github.com/bjack205/BilinearControl.jl/blob/00e4e976db1d65de4b3457fc9180d3d75d2e3002/examples/cartpole_eDMD_lqr.ipynb} and \url{https://github.com/bjack205/BilinearControl.jl/blob/00e4e976db1d65de4b3457fc9180d3d75d2e3002/examples/cartpole_eDMD_lqr_swing_up.ipynb}.

\subsection{Stabilizing using LQR}

To collect data, a nominal LQR controller is designed for stabilizing the pendulum about the top. Multiple trajectories are then generated for randomized initial condition using the linearized dynamics. The data is captured at 50Hz and 50 trajectories were generated for training the EDMD models.

To learn the EDMD models, the set of eigenfunctions is chosen to be $[x, sin(x), cos(x), sin(2x), sin(4x), 2x^{2} - 1, 4x^{3} - 3x, 8x^{4} - 8x^{2} + 1]$. The polynomials are a set of chebyshev polynomials of the 1st kind up to an order of 4, and were chosen due to being orthogonal functions. For regularization of the LLS problem, a ridge regression regularization value of 10.1 is used. Once the EDMD models are learned, the jacobians are projected back into the original state space and linearized about the stabilization point so that the LQR feedback policy can be designed. This is due to the Hilbert space being uncontrollable, leading to instabilities when trying to generate LQR feedback matrices directly on the eigenfunctions.

The simulated stabilization trajectories for one of the test validation cases is depicted in Figure 1. The simulation reveals that LQR is unable to stabilize the pendulum in an upright position about the origin for the nominal model, while the LQR controller paired with the jacobian residual-penalizing EDMD model is able to successfully deal with the initial disturbance and converge back to the origin with the pendulum stabilized in the upright position. This is consistent with the mean squared error of the predicted state, where the EDMD with the jacobian residual-penalization reduces the error of the nominal EDMD model by nearly 75\%.

\begin{figure}[thpb]
  \centering
  \includegraphics[scale=0.4]{Selection_010.png}
  \caption{LQR-generated stabilization trajectories based on nominal EDMD and EDMD with jacobian residual-penalization}
  \label{figurelabel}
\end{figure}

\begin{table}[h]
\begin{center}
\begin{tabular}{|c|c c|}
\hline
 & Training Data & Test Data\\
\hline
Nominal EDMD & 2.56e-2 & 4.5e-2\\
Jacobian-Penalty EDMD & 6.21e-3 & 6.36e-3\\
\hline
\end{tabular}
\end{center}
\caption{Mean squared error of state predictions of LQR-generated trajectories based on nominal EDMD and EDMD with jacobian residual-penalization}
\end{table}


\subsection{Tracking Swing-up using TVLQR}

In addition to stabilizing about a fixed point, the learned EDMD model with jacobian residual-penalization was tested on tracking a reference swing-up trajectory using a time-varying LQR controller (TVLQR). For data collection, 40 swing-up trajectories were generated using ALTRO, a nonlinear MPC solver \cite{13}. The bilinear EDMD model was learned using the swing-up trajectory data with the same eigenfunctions as the stabilization study. In addition, like the previous stabilization study, the bilinear jacobians were projected back to the original state space before being linearized about the reference swing-up trajectory.

The simulation of the TVLQR controller tracking a reference swing-up trajectory is depicted in Figure 2. While the TVLQR controller is able to use the projected bilinear jacobians to successfully track through most of the swing up trajectory, the TVLQR generated trajectory interestingly diverges from the stabilization point towards the end of the trajectory. This is despite LQR being highly successful in the previous stabilization study. Therefore, this deviation is likely due to the cost matrices of the TVLQR controller requiring further tuning.

\begin{figure}[thpb]
  \centering
  \includegraphics[scale=0.4]{Selection_006.png}
  \caption{TVLQR-generated tracking trajectories based on EDMD with jacobian residual-penalization. The reference trajectory models a swing-up before stabilizing the pendulum in an upright position}
  \label{figurelabel}
\end{figure}

\section{CONCLUSIONS}

This paper presented a method that improves upon the nominal EDMD model in order to learn more accurate, lifted, bilinear models by adding an additional penalty on the dynamics jacobians in the LLS regression. This allows the identification of the learned Koopman model to incorporate important derivative information, rather than just relying on only the discrete history of the states. Through a simulated cartpole, we demonstrated that EDMD with a penalization of the jacobian residuals is able to successfully both stabilize and track a swing-up trajectory using an LQR and TVLQR controller, which fails with a learn model using the nominal EDMD.

Future work includes extending the control study to design a linear and nonlinear MPC solver with actuation and state constraints. In addition, other sparsity promoting regularization methods, such as Lasso regression and sequential thresholded least-squares, can be implemented to further improve the EDMD model. In addition, data-driven learning of the eigenfunctions may offer performance improvements with more compact Koopman models.

\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

\begin{thebibliography}{99}

\bibitem{1} S. L. Brunton, M. Budišić, E. Kaiser, and J. N. Kutz, “Modern Koopman Theory for Dynamical Systems,” SIAM Review, vol. 64, no. 2, pp. 229–340, 2022, doi: 10.1137/21M1401243.

\bibitem{2} A. Surana, “Koopman operator based observer synthesis for control-affine nonlinear systems,” in 2016 IEEE 55th Conference on Decision and Control (CDC), 2016, pp. 6492–6499. doi: 10.1109/CDC.2016.7799268.

\bibitem{3} C. Folkestad, D. Pastor, I. Mezić, R. Mohr, M. Fonoberova, and J. W. Burdick, “Extended Dynamic Mode Decomposition with Learned Koopman Eigenfunctions for Prediction and Control,” 2020 American Control Conference (ACC), pp. 3906–3913, 2020.

\bibitem{4} I. Abraham, G. D. L. Torre, and T. D. Murphey, “Model-Based Control Using Koopman Operators,” ArXiv, vol. abs/1709.01568, 2017.

\bibitem{5} G. Mamakoukas, M. L. Castaño, X. Tan, and T. D. Murphey, “Local Koopman Operators for Data-Driven Control of Robotic Systems,” Robotics: Science and Systems XV, 2019.

\bibitem{6} I. Abraham and T. D. Murphey, “Active Learning of Dynamics for Data-Driven Control Using Koopman Operators,” 2019, doi: 10.48550/ARXIV.1906.05194.

\bibitem{7} D. Bruder, B. Gillespie, C. D. Remy, and R. Vasudevan, “Modeling and Control of Soft Robots Using the Koopman Operator and Model Predictive Control,” 2019, doi: 10.48550/ARXIV.1902.02827.

\bibitem{8} D. Bruder, X. Fu, R. B. Gillespie, C. D. Remy, and R. Vasudevan, “Koopman-based Control of a Soft Continuum Manipulator Under Variable Loading Conditions.” arXiv, 2020. doi: 10.48550/ARXIV.2002.01407.


\bibitem{9} C. Bakker, W. S. Rosenthal, and K. E. Nowak, “Koopman Representations of Dynamic Systems with Control,” ArXiv, vol. abs/1908.02233, 2019.

\bibitem{10} D. Bruder, X. Fu, and R. Vasudevan, “Advantages of Bilinear Koopman Realizations for the Modeling and Control of Systems With Unknown Dynamics,” IEEE Robotics and Automation Letters, vol. 6, pp. 4369–4376, 2021.

\bibitem{11} C. Folkestad and J. W. Burdick, “Koopman NMPC: Koopman-based Learning and Nonlinear Model Predictive Control of Control-affine Systems.” arXiv, 2021. doi: 10.48550/ARXIV.2105.08036.

\bibitem{12} S. L. Brunton, J. L. Proctor, and J. N. Kutz, “Sparse Identification of Nonlinear Dynamics with Control (SINDYc).” arXiv, 2016. doi: 10.48550/ARXIV.1605.06682.

\bibitem{13} T. A. Howell, B. E. Jackson, and Z. Manchester, “ALTRO: A Fast Solver for Constrained Trajectory Optimization,” in 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2019, pp. 7674–7679. doi: 10.1109/IROS40897.2019.8967788.


\end{thebibliography}

\end{document}
