\documentclass{article}

%\usepackage{corl_2022} % Use this for the initial submission.
\usepackage[final]{corl_2022} % Uncomment for the camera-ready ``final'' version.
%\usepackage[preprint]{corl_2022} % Uncomment for pre-prints (e.g., arxiv); This is like ``final'', but will remove the CORL footnote.
\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
\usepackage{mathrsfs}
\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{hyperref}
\usepackage{caption}
\captionsetup[table]{position=bottom}   %% or below
\usepackage{cite}
\usepackage{brian}

\title{Extended Dynamic Mode Decomposition with Jacobian Residual Penalization for Learning Bilinear, Control-affine Koopman Models}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

% NOTE: authors will be visible only in the camera-ready and preprint versions (i.e., when using the option 'final' or 'preprint'). 
% 	For the initial submission the authors will be anonymized.

\author{
  Brian E. Jackson \\
  Robotics Institute \\
  Carnegie Mellon University\\
  \texttt{brianjackson@cmu.edu} \\
  %% examples of more authors
  \and
  Jeong Hun Lee \\
  Robotics Institute\\
  Carnegie Mellon University\\
  \texttt{jeonghunlee@cmu.edu} \\
  \and
  Kevin Tracy \\
  Robotics Institute\\
  Carnegie Mellon University\\
  \texttt{ktracy@cmu.edu} \\
  \and
  Zachary Manchester \\
  Robotics Institute\\
  Carnegie Mellon University\\
  \texttt{zacm@cmu.edu} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}


\begin{document}
\maketitle

%===============================================================================

\begin{abstract}
    Data-driven, Koopman-based learning methods offer a practical and more efficient technique to control nonlinear dynamical systems by lifting the dynamics into a linear space of observable functions. However, many Koopman learning frameworks specifically learn \emph{lifted linear} models, which assume linearity with respect to the controls, without also incorporating any \emph{derivative} information of the system. This paper presents an extension of the commonly-used Extended Dynamic Mode Decomposition (EDMD) method for learning a \emph{lifted bilinear}, control-affine dynamical system while also penalizing residuals of the \emph{jacobians} in addition to the states. We show that this regularization technique can be used to incorporate prior model knowledge in the EDMD process to reduce overfitting, resulting in more accurate learned, dynamics models for control, where the learned jacobians can be exploited in the feedback policy. This benefit of penalizing the jacobian residual is highlighted in both a simulated and empirical quadrotor example, for which LQR and MPC can successfully stabilize about a fixed point and track a trajectory respectively.
\end{abstract}

% Two or three meaningful keywords should be added here
\keywords{Koopman, Learning, Dynamics} 

%===============================================================================

\section{Introduction}
    Controlling complex, underactuated, and highly nonlinear autonomous systems remains an active area 
    of research in robotics, despite decades of previous work exploring effective algorithms and the 
    development of substantial theoretical analysis. Classical approaches typically rely on local 
    linear approximations of the nonlinear system, which are then used in any of a multitude of linear 
    control techniques, such as PID, pole placement, Bode analysis, H-infinity, LQR, or linear MPC. 
    These approaches only work well if the states of the system always remain close to the linearization 
    point or reference trajectory. The region for which these linearizations remain valid can be extremely 
    small for highly nonlinear systems.
    Alternatively, model-based methods for nonlinear control based on optimal control have shown great 
    success, as long as the 
    model is well known and an accurate estimate of the global state can be provided. These model-based 
    techniques leverage centuries of insight into dynamical systems and have demonstrated incredible 
    performance on extremely complicated autonomous systems \todo{add citations for some recent work}.
    On the other hand, data-driven techniques such as reinforcement learning have received tremendous 
    attention over the last decade and have begun to demonstrate impressive performance and robustness 
    for complicated robotic systems in unstructured environments \todo{cite a few RL results, including
    Marco Hutter's recent stuff}. While these approaches are attractive since they require little to no
    previous knowledge about the system, they often require large amounts of data and 
    fail to generalize outside of the domain or task on which they were ``trained.''
    
    In this work we propose a novel method that combines the benefits of model-based and data-driven methods, based on recent work  applying Koopman Operator Theory to controlled dynamical systems 
    \todo{cite a few Koopman papers,  including the CalTech ones}. 
    By leveraging data collected from an unknown dynamical system along with
    derivative information from an approximate analytical model, we can efficiently learn a bilinear 
    representation of the system dynamics that performs well when used in traditional model-based control
    techniques such as linear MPC. The result is nonlinear dynamical system that is expressive enough 
    to capture the full nonlinear dynamics across a broad range of the state space, but has a well-defined 
    structure that is very amenable to specialized optimization-based controllers. By leveraging information
    from an analytical model, we can dramatically reduce the number of samples required to learn a good 
    approximation of the true nonlinear dynamics. 
    
    \todo{bullet out contributions.}
    
    \todo{add summary of paper layout.}
	
    % Linear systems benefit from a great amount of efficient algorithms for practical, online control. However, many real-world problems are modeled as nonlinear systems (e.g. fluid dynamics, double pendulum, etc.) but suffer from the lack of a general framework and efficient algorithms for efficient, real-time control tasks. Therefore, it is common to linearize the nonlinear system about a fixed point for stabilization tasks or a reference trajectory for tracking. However, these linearizations are local and do not model the entire space of the dynamical system.

    % The Koopman Operator offers a technique to capture the global behavior of a nonlinear dynamical system by "lifting" the system into an infinite space of scalar-valued functions of the states \cite{1}. This function space is canonically known as the Hilbert space and the functions are known as \emph{observables}. This Koopman representation of the dynamics suggests that any nonlinear function can be represented by an infinite linear combination of observables. However, an infinite dimensional space is impractical, so in application, the goal becomes to find an appropriate, finite basis of observable functions. In the Koopman Canonical Transform (KCT), the goal is specifically to find enough observables whose linear combination can also be used to approximately represent the state \cite{2}. These observables are also known as \emph{eigenfunctions}. Commonly, choosing appropriate eigenfunctions stems from engineering intuition and system knowledge, but recent works have also aimed to use data-driven methods \cite{3}.
    % For identifying Koopman models, data-driven methods have gained popularity. Specifically, Dynamic Mode Decomposition (DMD) and Extended Dynamic Mode Decomposition (EDMD) have been widely used to identify best-fit, approximate, linear Koopman models for various nonlinear, robotic systems \cite{4, 5, 6, 7, 8}. Both methods involve solving a linear, least squares (LLS) regression over the lifted data (corresponding eigenfunction values) to generate a best-fit, approximate Koopman representation of the original dynamics. While these lifted, linear models pair well with existing, efficient algorithms, there is no guaranteed that these Koopman models are valid global representations of the system. This is due to linear Koopman approximations inherently assuming that the model is linear with respect to the control inputs in the Hilbert space, which further restricts the subspace in which the linear model is learned \cite{9}. Recently, small attention has been given to use EDMD to identify bilinear, control-affine Koopman models for nonlinear MPC with improved performance over their linear counterparts \cite{10, 11}. These bilinear representations aim to preserve some of the structure and computational efficiency of linear systems while incorporating nonlinearity with respect to the control inputs.
    % While works have improved on lifted, linear models by learning lifted, bilinear representations, little consideration has also been given to regularizing techniques in EDMD. When learning the Koopman model, Lasso (L1) regularization is commonly implemented to promote sparsity in the regression, and the widely-known SINDYc algorithm implements the more computationally-efficient, sequential thresholded least-squares method \cite{12}. However, these implementations only look to penalize the residual of the states, when the derivative information of the system can also be used to improve the lifted model. Towards this goal, this paper presents a new EDMD framework that also penalizes the jacobian residual in addition to the state residuals in the LLS regression when learning the lifted, bilinear Koopman model. First, preliminary/background information on the Koopman operator, the Koopman Canonical Transform, and EDMD will be provided in Section II. Next, the EDMD framework with the incorporated jacobian residual-penalization will be presenting in Section III. Finally, the resulting Koopman model will be demonstrated on a simulated cartpole with an LQR controller in Section IV before we conclude in Section V.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Background and Related Work 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background and Related Work} \label{sec:Preliminaries/Background}

\subsection{The Koopman Operator}
The theoretical underpinnings of the Koopman operator and its application to dynamical systems has been 
extensively studied, especially within the last decade \todo{cite some important theoretical works on 
Koopman theory here}. Rather than describe the theory in detail, we highlight the key concepts employed
by the current work, and defer the motivated reader to the existing literature on Koopman theory.

We start by assuming we have some discrete approximation a of controlled nonlinear, time-dynamical system 
whose underlying continuous dynamics are Lipschitz continuous:
\begin{equation} \label{eq:discrete_dynamics}
    x_{k+1} = f(x_k, u_k)
\end{equation}
where $x \in \mathcal{X} \subseteq \R^{N_x}$ is the state vector and $u_k \in \R^{N_u}$ is the 
control vector.
This discrete approximation can be obtained for any continuous dynamical system in many ways, including 
implicit and explicit Runge-Kutta methods, or by solving the Discrete Euler-Lagrange equations 
\todo{add citations}.

The key idea behind the Koopman operator is that the nonlinear finite-dimensional discrete dynamics 
\eqref{eq:discrete_dynamics} can be represented by an infinite-dimensional \textit{bilinear} system:
\begin{equation} \label{eq:bilinear_dynamics}
    y_{k+1} = A y_k + B u_k + \sum_{i=1}^m u_{k,i} C_i y_k = g(y,u)
\end{equation}
where $y = \phi(x)$ is a mapping from the finite-dimensional state space $\mathcal{X}$ to the (possibly) 
infinite-dimensional Hilbert space of \textit{observables} $y \in \mathcal{Y}$. We also assume the inverse 
map is approximately linear: $x = G y$. In practice, we approximate
\eqref{eq:discrete_dynamics} by choosing $\phi$ to be some arbitrary finite set of nonlinear functions 
of the state variables, which in general include the states themselves such that the linear mapping 
$G \in \R^{N_x \times N_y}$ is  exact. 
Intuitively, $\phi$ ``lifts'' our states into a higher dimensional space where 
the dynamics are approximately (bi)linear, effectively trading dimensionality for (bi)linearity. This idea 
should be both unsurprising and familiar to most roboticsts, since similar techniques have already been 
employed in other forms, such as maximal-coordinate representations of rigid body dynamics 
\todo{add citations}, the ``kernel trick'' for state-vector machines \todo{add citation}, or the observation
that solving large, sparse nonlinear optimization problems is often more effective than solving small,
tightly-coupled dense problems \todo{add citations from the trajectory optimization literature}.

The lifted bilinear system \eqref{eq:bilinear_dynamics} can be easily learned from samples of the system 
dynamics $(x_i^+,x_i,u_i)$ (where $x^+$ is the state at the next time step) using extended Dynamic Mode 
Decomposition (eDMD), which is just the application of linear least squares (LLS) to the lifted states.
Details of this method will be covered later when we introduce our adaptation of eDMD and present an 
effective numerical technique for solving the resulting LLS problems.

% Before introducing the Koopman operator, we introduce the continuous nonlinear, time-dynamical system without controls:
% \begin{equation}
%     \dot{x} = f(x)
% \end{equation}
% with state $x \in \mathcal{X} \subseteq \R^{n}$ and $f$ being Lipschitz continuous on $\mathcal{X}$. The flow map of this dynamical system is denoted as $F_{t}(x)$ where $\frac{d}{dt}F_{t}(x) = f(F_{t}(x))$. In discrete time, the dynamical system becomes:

% \begin{equation}
%     \dot{x}_{k+1} = F_{t}(x_{k})
% \end{equation}

% The Koopman operator of this dynamical system is defined as:

% $$
% K_{t}{\psi} = \psi \circ F_{t} \eqno{(3)}
% $$
% for all $\psi \in \mathcal{C(X)}$, where $\mathcal{C(X)}$ represents the infinite dimensional Hilbert space of continuous functions. We refer to these functions $\psi$ as \emph{observables} that "lift" the function into the Hilbert space. The operator $\circ$ denotes the composition operator ($g \circ f = g(f(x))$). The Koopman operator suggests that the continuous, nonlinear dynamical system in $\mathcal{X}$ can be globally represented by an infinite dimensional, linear system in $\mathcal{C(X)}$. If we look at the Koopman operator in discrete time,
% $$
% K_{t}{\psi(x_{k})} = \psi(x_{k+1}) \eqno{(4)}
% $$
% this more clearly suggests that we can represent the nonlinear dynamics as a linear system in $\mathcal{C(X)}$ in discrete time as well.

% \subsection{The Koopman Canonical Transform}

% Before introducing the Koopman Canonical Transform (KCT), we first introduce the \emph{eigenfunctions} $\phi \in \mathcal{C(X)}$. These are specific types of observables that evolve linearly with $F_{t}$:
% $$
% K_{t}\phi(x) = e^{\lambda t}\phi(x) \eqno{(5)}
% $$
% where $\lambda \in \mathbb{C}$ are the \emph{eigenvalues} corresponding to $\phi(x)$.

% Instead of creating a lifted, linear representation, the KCT specifically incorporates the control inputs in the dynamics $\Dot{x} = f(x, u)$ and transforms the dynamics into a lifted, bilinear form where the observables $\psi(x)$ are the eigenfunctions $\phi(x)$ of the Koopman operator \cite{2}. This assumes that the state itself can be represented by a finite, linear combination of the eigenfunctions:
% $$
% x = \sum_{i=1}^{n} v_{i}\phi_{i}(x) \; \forall \; x \in \mathcal{X} \eqno{(6)}
% $$
% where $v_{i} \in \mathbb{C}^{d}$. Using these eigenfunctions $\phi_{i}(x)$ as nonlinear basis in $\mathcal{C(X)}$ suggests a transformation from $\mathcal{X}$ to $C(X)$:
% $$
% x = gz \eqno{(7)}
% $$
% where $z = \phi(x) = [\phi_{1}(x) \; \phi_{2}(x) \; ... \; \phi_{n}(x)]^{T}$ and $g = [v_{1} \; v_{2} \; ... \; v_{n}]$. The lifted, bilinear Koopman model from the KCT is defined as:
% $$
% \Dot{z} = A^{z}z + \sum_{i=1}^{m} u_{i}C_{i}z \eqno{(8)}
% $$
% where $z \in \mathbb{R}^{n}, n < \infty$. In discrete time, the bilinear Koopman model becomes:
% $$
% x_{k} = gz_{k} \eqno{(9)} \\
% $$
% $$
% z_{k+1} = A^{z}z_{k} + \sum_{i=1}^{m} u_{k,i}C_{i}z_{k} \eqno{(10)}
% $$

% \subsection{Extended Dynamic Mode Decomposition}

% To learn an approximate, lifted bilinear model as suggested by the KCT, Extended Dynamic Mode Decomposition (EDMD) is used. This is a data-driven method that takes data (i.e. time history of the state) and splits it into 2 datasets:
% $$
% \mathbf{X} = [x_{1} \; x_{2} \; ... \; x_{N-1}] \qquad \mathbf{X}' = [x_{2} \; x_{3} \; ... \; x_{N}] \eqno{(12)} \\
% $$
% The data is then lifted into the Hilbert space with a chosen set of eigenfunctions $\phi(x)$, which is based on system knowledge, engineering intuition, and/or data-driven methods \cite{3}:
% $$
% \mathbf{Z} = [\phi(x_{1}) \; \phi(x_{2}) \; ... \; \phi(x_{N-1})] = [z_{1} \; z_{2} \; ... \; z_{N-1}]
% $$
% $$
% \mathbf{Z}' = [\phi(x_{2}) \; \phi(x_{3}) \; ... \; \phi(x_{N})] = [z_{2} \; z_{3} \; ... \; z_{N}] \eqno{(13)} \\
% $$
% In order to properly learn a bilinear representation, specifically the bilinear coefficients, the control inputs must also be incorporated in the lifted data:
% $$
% \mathbf{Z_{u}} = \begin{bmatrix}
% z_{1} & z_{2} & ... & z_{N-1} \\
% z_{1}u_{1} & z_{2}u_{1} & ... & z_{N-1}u_{1} \\
% z_{1}u_{2} & z_{2}u_{2} & ... & z_{N-1}u_{2} \\
% ... & ... & ... & ... \\
% z_{1}u_{m} & z_{2}u_{m} & ... & z_{N-1}u_{m} \\
% \end{bmatrix} \eqno{(14)}
% $$
% Learning both the bilinear Koopman model and the $\mathcal{X}$-to-$\mathcal{C(X)}$ transformation can then be formulated as a linear least-squares (LLS) regression problem:
% $$
% \min_{E} ||Z' - EZ_{u}||^{2} \eqno{(15)}
% $$
% $$
% \min_{g} ||X - gZ||^{2} \eqno{(16)}
% $$
% where $E = [A^{z} \; C_{1} \; C_{2} \; ... \; C_{m}]$. To prevent overfitting, Lasso ($l_{1}$) regularization is used to promote sparsity in addition to other methods, such as the sequential thresholded least-squares method as seen in SINDYc \cite{12}. One thing to note is that due to EDMD learning over a discrete time history, EDMD learns a discrete bilinear model.


\subsection{Model-Predictive Control}
\todo{add background on MPC?}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Methodology
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{EDMD with Jacobian Residual-Penalization}
Existing Koopman-based approaches to learning dynamical systems only rely on samples of the unknown 
dynamics. Here we present a novel method for incorporating prior knowledge about the dynamics by adding 
derivative information of an approximate model into the data set to be learned via eDMD.

Given $P$ samples of the dynamics $(x_i^+, x_i, u_i)$, and an approximate discrete dynamics model 
\begin{equation}
    x^+ = \tilde{f}(x,u)
\end{equation}
we can evaluate the Jacobians of our approximate model $\hat{f}$ at each of the sample points: 
$\tilde{A}_i = \pdv{\tilde{f}}{x}, \tilde{B}_i = \pdv{\tilde{f}}{x}$. After choosing nonlinear mapping
$\phi : \R^{N_x} \mapsto \R^{N_y}$ We then want to find a bilinear dynamics model 
\eqref{eq:bilinear_dynamics} that matches the Jacobians of our approximate model, while also matching 
our dynamics samples. If we define $\hat{A}_j \in \R^{N_x \times N_x}$ and 
$\hat{B}_j \in \R^{N_x \times N_u}$ to be 
the Jacobians of our bilinear dynamics model, projected back into the original state space, our objective 
is to find the matrices $A \in \R^{N_y \times N_y},B \in \R^{N_y \times N_u}$, and 
$C_{1:m} \in \R^{N_u} \times \R^{N_y \times N_y}$ that minimize the following objective:

\begin{equation} \label{eq:lls_objective}
    (1- \alpha) \sum_{j=1}^P \norm{\hat{y}_j - y_j^+}_2^2 + 
        \alpha  \sum_{j=1}^P \norm{\hat{A}_j - \tilde{A}_j}_2^2 + 
                             \norm{\hat{B}_j - \tilde{B}_j}_2^2 
\end{equation}
where $\hat{y}_j^+ = g\left(\phi(x_j), u_j\right)$ is the output of our bilinear  dynamics model, 
and $y_j^+ = \phi(y_j^+)$ is the actual lifted state (i.e. observables) at the next time step.

While not immediately apparent, we can minimize \eqref{eq:lls_objective} using linear least-squares, using 
techniques similar to those used previously in the literature \todo{cite CalTech papers}.

To start, we combine all the data we're trying to learn in a single matrix:
\begin{equation}
    E = \begin{bmatrix} A & B & C_1 & \dots & C_m \end{bmatrix} \in \R^{N_y \times N_z} \\
\end{equation}
where $N_z = N_y + N_u + N_y \cdot N_u$.
We now rewrite the terms in \eqref{eq:lls_objective} in terms of $E$. By defining the vector 
\begin{equation}
    z = \begin{bmatrix} y^T & u^T & u_1 y^T & \dots & u_m y^T \end{bmatrix} \in \R^{N_z} 
\end{equation}
we can write down 
the output of our bilinear dynamics \eqref{eq:bilinear_dynamics} as 
\begin{equation} \label{eq:bilinear_dynamics_z}
    \hat{y}^+ = E z.
\end{equation}
The projected Jacobians of our bilinear model, $\hat{A}$ and $\hat{B}$, are simply the Jacobians 
of the bilinear dynamics in terms of the original state. We obtain these dynamics by ``lifting`` 
the state via $\phi$ and then projecting back onto the original states using $G$:
\begin{equation} \label{eq:projected_dynamics}
    x^+ = G \left( A \phi(x) + B u + \sum_{i=1}^m u_i C_i \phi(x) \right)  = \hat{f}(x,u) 
\end{equation}
Differentiating these dynamics give us our projected Jacobians:
\begin{subequations} \label{eq:projected_jacobians}
\begin{align}
    \hat{A}_j &= G \pdv{\hat{f}}{x}\left(x_j,u_j\right) 
               = G \left(A + \sum_{i=1}^m u_{j,i} C_i \right) \Phi(x_j)
            %   = G A_j^x \phi(x_j)
               = G E \bar{A}(x_j,u_j) = G E \bar{A}_j \\
    \hat{B}_i &= G \pdv{\hat{f}}{u}\left(x_j,u_j\right) 
               = G \Big(B + \begin{bmatrix} C_1 x_j & \dots & C_m x_j \end{bmatrix} \Big)
            %   = G B_j^u
               = G E \bar{B}(x_j,u_j) = G E \bar{B}_j
\end{align}
\end{subequations}
where $\Phi(x) = \pdv*{\phi}{x}$ is the Jacobian of the nonlinear map $\phi$, and
\begin{equation}
    \bar{A}(x,u) =  \begin{bmatrix} 
        I \\ 0 \\ u_1 I \\ u_2 I \\ \vdots \\ u_m I 
    \end{bmatrix} \in \R^{N_z \times N_x}, \quad
    \bar{B}(x,u) = \begin{bmatrix} 
        0 \\ 
        I \\ 
        [x \; 0 \; ... \; 0] \\
        [0 \; x \; ... \; 0] \\
        \vdots \\
        [0 \; 0 \; ... \; x] \\
    \end{bmatrix} \in \R^{N_z \times N_u}.
\end{equation}
Substituting \eqref{eq:bilinear_dynamics_z} and \eqref{eq:projected_jacobians} into \eqref{eq:lls_objective},
we can rewrite our LLS problem as:
\begin{align}
    \underset{E}{\text{minimize}} \;\; 
        \sum_{j=0}^P
        (1-\alpha) \norm{E z_j - y_j^+}_2^2 + 
           \alpha  \norm{G E \bar{A}_j - \tilde{A}_j}_2^2 + 
           \alpha  \norm{G E \bar{B}_j - \tilde{B}_j}_2^2 
\end{align}
which is equivalent to
\begin{align} \label{opt:lls_matrix}
    \underset{E}{\text{minimize}} \;\; 
        (1-\alpha) \norm{E \mathbf{Z_{1:P}} - \mathbf{Y^+_{1:P}} }_2^2 + 
           \alpha  \norm{G E \mathbf{\bar{A}_{1:P}} - \mathbf{\tilde{A}_{1:P}}}_2^2 + 
           \alpha  \norm{G E \mathbf{\bar{B}_{1:P}} - \mathbf{\tilde{B}_{1:P}}}_2^2
\end{align}
where $\mathbf{Z_{1:P}} \in \R^{N_z \times P} = [z_1 \; z_2 \; ... \; z_P]$ horizontally concatenates all of the samples 
(equivalent definition for 
$\mathbf{Y^+_{1:P}} \in \R^{N_y \times P}$, 
$\mathbf{\bar{A}_{1:P}} \in \R^{N_z \times N_x \cdot P}$, 
$\mathbf{\tilde{A}_{1:P}} \in \R^{N_z \times N_x \cdot P}$,
$\mathbf{\bar{B}_{1:P}} \in \R^{N_z \times N_u \cdot P}$, and 
$\mathbf{\tilde{B}_{1:P}} \in \R^{N_z \times N_u \cdot P}$ ).

We can rewrite \eqref{opt:lls_matrix} in standard form using the ``vec trick''
\begin{equation} \label{eq:vectrick}
    \text{vec}(A X B) = (B^T \otimes A) \text{vec}(X)
\end{equation}
where $\text{vec}(A)$ stacks the columns of $A$ into a single vector.

Setting $E$ in \eqref{opt:lls_matrix} equal to $X$ in \eqref{eq:vectrick}, we get
\begin{align} \label{opt:lls_matrix}
    \underset{E}{\text{minimize}} \;\;  
    \norm{
        \begin{bmatrix}
            (\mathbf{Z_{1:P}})^T \otimes I_{N_y} \\
            (\mathbf{\bar{A}_{1:P}})^T \otimes G \\
            (\mathbf{\bar{G}_{1:P}})^T \otimes G \\
        \end{bmatrix}
        \text{vec}(E)
        +
        \begin{bmatrix}
            \text{vec}(\mathbf{Y^+_{1:P}}) \\
            \text{vec}(\mathbf{\tilde{A}_{1:P}}) \\
            \text{vec}(\mathbf{\tilde{G}_{1:P}})
        \end{bmatrix}
    }_2^2
\end{align}
such that the matrix of cofficients has $(N_y + N_x^2 + N_x \cdot N_u) \cdot P$ rows and 
$N_y \cdot N_z$ columns.

% As seen in (15), the LLS optimization problem only minimizes the sum-of-squares of the eigenfunction residuals, which are functions of the state. As a consequence, the dynamics jacobians are not taken into account in the learning problem; more specifically, the residuals of the dynamics jacobians themselves are not penalized, even though the goal of EDMD is to learn these jacobian matrices. Therefore, incorporating the jacobian residuals may lead to a more accurate bilinear Koopman representation of the nonlinear dynamics.

% To formulate the jacobian residuals for the LLS regression of the EDMD, a time history of the dynamics jacobians must also be recorded as part of the data:
% $$
% \mathbf{A^{x}} = [A^{x}_{1} \; A^{x}_{2} \; ... \; A^{x}_{N-1}] \qquad \mathbf{B^{x}} = [B^{x}_{1} \; B^{x}_{2} \; ... \; B^{x}_{N-1}] \eqno{(17)} \\
% $$
% In addition, the jacobians of the bilinear Koopman model with respect to the original states $x$ and controls $u$ can be determined as:
% $$
% \frac{\partial Z_{k+1}}{x_{k}} = (A^{z} + \sum_{i=1}^{m} u_{k,i}C_{i})\frac{\partial z_{k}}{\partial x_{k}} = E\hat{A}
% $$
% $$
% \frac{\partial Z_{k+1}}{u_{k}} = B^{z} + [C_{1}z_{k} \; C_{2}z_{k} \; ... \; C_{m}z_{k}] = E\hat{B} \eqno{(18)} 
% $$
% where:
% $$
% \hat{A}_{k} = \begin{bmatrix} \frac{\partial z_{k}}{\partial x_{k}} \\ 0 \\ u_{k,1}\frac{\partial z_{k}}{\partial x_{k}} \\ u_{k,2}\frac{\partial z_{k}}{\partial x_{k}} \\ ... \\ u_{k, m}\frac{\partial z_{k}}{\partial x_{k}} \end{bmatrix} \qquad \hat{B}_{k} = \begin{bmatrix} 0 \\ I \\ [x_{k} \; 0 \; ... \; 0] \\ [0 \; x_{k} \; ... \; 0] \\ ... \\ [0 \; 0 \; ... \; x_{k}] \end{bmatrix} \eqno{(19)}
% $$

% The EDMD with the jacobian residual-penalization can then be written as:
% $$
% \min_{E} (1-\alpha)||Z' - EZ_{u}||^{2} + \alpha||A^{x} - gE\hat{A}||^{2} + \alpha||B^{x} - gE\hat{B}||^{2} \eqno{(20)}
% $$
% where $Z_{u}$ has been slightly changed to take into account a linear term for $u$:
% $$
% \mathbf{Z_{u}} = \begin{bmatrix}
% z_{1} & z_{2} & ... & z_{N-1} \\
% u_{1} & u_{2} & ... & u_{N-1} \\
% z_{1}u_{1} & z_{2}u_{1} & ... & z_{N-1}u_{1} \\
% z_{1}u_{2} & z_{2}u_{2} & ... & z_{N-1}u_{2} \\
% ... & ... & ... & ... \\
% z_{1}u_{m} & z_{2}u_{m} & ... & z_{N-1}u_{m} \\
% \end{bmatrix} \eqno{(21)}
% $$

\subsection{Efficient Recursive Least Squares}

%===============================================================================

% \section{Simulated Quadrotor Results}
% \label{sec:simulation}
%     \subsection{Quadrotor System Details}
    
%     A Cartpole model was chosen with the following model-based, nonlinear dynamics:
    
%     $$
%     \begin{bmatrix} \Dot{v} \\ \Dot{\omega} \end{bmatrix} = -\begin{bmatrix}
%     m_{c} + m_{p} & m_{p}lcos(\theta) \\
%     m_{p}lcos(\theta) & m_{p}l^{2} \end{bmatrix}^{-1}
%     $$
%     $$\bigg(\begin{bmatrix}
%     0 & -m_{p}\omega lcos(\theta) \\
%     0 & 0 \end{bmatrix} \begin{bmatrix}
%     v \\ \omega \end{bmatrix} + \begin{bmatrix}
%     0 \\
%     m_{p}glsin(\theta)\\
%     \end{bmatrix} - \begin{bmatrix} 1 \\ 0 \end{bmatrix}u\bigg) \eqno{(22)}
%     $$
%     with states $x = [y, \theta, v, \omega]^{T}$, where $y, \theta$ describe the position of the cartpole and angle of the pendulum respectively and $v, \omega$ describe the respective velocities. $m_{c}, m_{p}$ describe the masses of the cartpole and pendulum respectively with $l$ describing the length of the pendulum. $g$ denotes the gravitational constant.
    
%     To compare our bilinear EDMD with the jacobian residual-penalization to the nominal bilinear EDMD framework, LQR controllers were designed for each EDMD-generated model for 2 tasks: 1) stabilize the cartpole at $[0, \pi]$ using time-invarient LQR 2) track a swing-up reference trajectory using tim-varying LQR (TVLQR). The respective code for each task can be found on GitHub at \url{https://github.com/bjack205/BilinearControl.jl/blob/00e4e976db1d65de4b3457fc9180d3d75d2e3002/examples/cartpole_eDMD_lqr.ipynb} and \url{https://github.com/bjack205/BilinearControl.jl/blob/00e4e976db1d65de4b3457fc9180d3d75d2e3002/examples/cartpole_eDMD_lqr_swing_up.ipynb}.
    
%     \subsection{Learning Simulated Quadrotor Dynamics}

%     To collect simulated data, a nominal LQR controller is designed for stabilizing the pendulum about the top. Multiple trajectories are then generated for randomized initial condition using the linearized dynamics. The data is captured at 50Hz and 50 trajectories were generated for training the EDMD models.
    
% \subsection{Stabilizing using LQR}
    
%     To learn the EDMD models, the set of eigenfunctions is chosen to be $[x, sin(x), cos(x), sin(2x), sin(4x), 2x^{2} - 1, 4x^{3} - 3x, 8x^{4} - 8x^{2} + 1]$. The polynomials are a set of chebyshev polynomials of the 1st kind up to an order of 4, and were chosen due to being orthogonal functions. For regularization of the LLS problem, a ridge regression regularization value of 10.1 is used. Once the EDMD models are learned, the jacobians are projected back into the original state space and linearized about the stabilization point so that the LQR feedback policy can be designed. This is due to the Hilbert space being uncontrollable, leading to instabilities when trying to generate LQR feedback matrices directly on the eigenfunctions.
    
%     The simulated stabilization trajectories for one of the test validation cases is depicted in Figure 1. The simulation reveals that LQR is unable to stabilize the pendulum in an upright position about the origin for the nominal model, while the LQR controller paired with the jacobian residual-penalizing EDMD model is able to successfully deal with the initial disturbance and converge back to the origin with the pendulum stabilized in the upright position. This is consistent with the mean squared error of the predicted state, where the EDMD with the jacobian residual-penalization reduces the error of the nominal EDMD model by nearly 75\%.
    
%     % \begin{figure}[thpb]
%     %   \centering
%     %   \includegraphics[scale=0.4]{Selection_010.png}
%     %   \caption{LQR-generated stabilization trajectories based on nominal EDMD and EDMD with jacobian residual-penalization}
%     %   \label{figurelabel}
%     % \end{figure}
    
%     \begin{table}[h]
%     \begin{center}
%     \begin{tabular}{|c|c c|}
%     \hline
%      & Training Data & Test Data\\
%     \hline
%     Nominal EDMD & 2.56e-2 & 4.5e-2\\
%     Jacobian-Penalty EDMD & 6.21e-3 & 6.36e-3\\
%     \hline
%     \end{tabular}
%     \end{center}
%     \caption{Mean squared error of state predictions of LQR-generated trajectories based on nominal EDMD and EDMD with jacobian residual-penalization}
%     \end{table}
    
    
%     \subsection{Tracking Swing-up using TVLQR}
    
%     % In addition to stabilizing about a fixed point, the learned EDMD model with jacobian residual-penalization was tested on tracking a reference swing-up trajectory using a time-varying LQR controller (TVLQR). For data collection, 40 swing-up trajectories were generated using ALTRO, a nonlinear MPC solver \cite{13}. The bilinear EDMD model was learned using the swing-up trajectory data with the same eigenfunctions as the stabilization study. In addition, like the previous stabilization study, the bilinear jacobians were projected back to the original state space before being linearized about the reference swing-up trajectory.
    
%     The simulation of the TVLQR controller tracking a reference swing-up trajectory is depicted in Figure 2. While the TVLQR controller is able to use the projected bilinear jacobians to successfully track through most of the swing up trajectory, the TVLQR generated trajectory interestingly diverges from the stabilization point towards the end of the trajectory. This is despite LQR being highly successful in the previous stabilization study. Therefore, this deviation is likely due to the cost matrices of the TVLQR controller requiring further tuning.
    
%     % \begin{figure}[thpb]
%     %   \centering
%     %   \includegraphics[scale=0.4]{Selection_006.png}
%     %   \caption{TVLQR-generated tracking trajectories based on EDMD with jacobian residual-penalization. The reference trajectory models a swing-up before stabilizing the pendulum in an upright position}
%     %   \label{figurelabel}
%     % \end{figure}

% %===============================================================================

% \section{Experimental Results}
% \label{sec:comparisons}

% %===============================================================================


% \section{Limitations} \label{sec:limitations} % NOTE: this section is required by CoRL

% %===============================================================================

% \section{Conclusion}
% \label{sec:conclusion}

%     This paper presented a method that improves upon the nominal EDMD model in order to learn more accurate, lifted, bilinear models by adding an additional penalty on the dynamics jacobians in the LLS regression. This allows the identification of the learned Koopman model to incorporate important derivative information, rather than just relying on only the discrete history of the states. Through a simulated cartpole, we demonstrated that EDMD with a penalization of the jacobian residuals is able to successfully both stabilize and track a swing-up trajectory using an LQR and TVLQR controller, which fails with a learn model using the nominal EDMD.
    
%     Future work includes extending the control study to design a linear and nonlinear MPC solver with actuation and state constraints. In addition, other sparsity promoting regularization methods, such as Lasso regression and sequential thresholded least-squares, can be implemented to further improve the EDMD model. In addition, data-driven learning of the eigenfunctions may offer performance improvements with more compact Koopman models.
    
% %===============================================================================

% \clearpage
% % The acknowledgments are automatically included only in the final and preprint versions of the paper.
% \acknowledgments{If a paper is accepted, the final camera-ready version will (and probably should) include acknowledgments. All acknowledgments go at the end of the paper, including thanks to reviewers who gave useful comments, to colleagues who contributed to the ideas, and to funding agencies and corporate sponsors that provided financial support.}

% %===============================================================================

% % no \bibliographystyle is required, since the corl style is automatically used.
% % \bibliography{example}  % .bib

% \begin{thebibliography}{99}

% \bibitem{1} S. L. Brunton, M. Budišić, E. Kaiser, and J. N. Kutz, “Modern Koopman Theory for Dynamical Systems,” SIAM Review, vol. 64, no. 2, pp. 229–340, 2022, doi: 10.1137/21M1401243.

% \bibitem{2} A. Surana, “Koopman operator based observer synthesis for control-affine nonlinear systems,” in 2016 IEEE 55th Conference on Decision and Control (CDC), 2016, pp. 6492–6499. doi: 10.1109/CDC.2016.7799268.

% \bibitem{3} C. Folkestad, D. Pastor, I. Mezić, R. Mohr, M. Fonoberova, and J. W. Burdick, “Extended Dynamic Mode Decomposition with Learned Koopman Eigenfunctions for Prediction and Control,” 2020 American Control Conference (ACC), pp. 3906–3913, 2020.

% \bibitem{4} I. Abraham, G. D. L. Torre, and T. D. Murphey, “Model-Based Control Using Koopman Operators,” ArXiv, vol. abs/1709.01568, 2017.

% \bibitem{5} G. Mamakoukas, M. L. Castaño, X. Tan, and T. D. Murphey, “Local Koopman Operators for Data-Driven Control of Robotic Systems,” Robotics: Science and Systems XV, 2019.

% \bibitem{6} I. Abraham and T. D. Murphey, “Active Learning of Dynamics for Data-Driven Control Using Koopman Operators,” 2019, doi: 10.48550/ARXIV.1906.05194.

% \bibitem{7} D. Bruder, B. Gillespie, C. D. Remy, and R. Vasudevan, “Modeling and Control of Soft Robots Using the Koopman Operator and Model Predictive Control,” 2019, doi: 10.48550/ARXIV.1902.02827.

% \bibitem{8} D. Bruder, X. Fu, R. B. Gillespie, C. D. Remy, and R. Vasudevan, “Koopman-based Control of a Soft Continuum Manipulator Under Variable Loading Conditions.” arXiv, 2020. doi: 10.48550/ARXIV.2002.01407.


% \bibitem{9} C. Bakker, W. S. Rosenthal, and K. E. Nowak, “Koopman Representations of Dynamic Systems with Control,” ArXiv, vol. abs/1908.02233, 2019.

% \bibitem{10} D. Bruder, X. Fu, and R. Vasudevan, “Advantages of Bilinear Koopman Realizations for the Modeling and Control of Systems With Unknown Dynamics,” IEEE Robotics and Automation Letters, vol. 6, pp. 4369–4376, 2021.

% \bibitem{11} C. Folkestad and J. W. Burdick, “Koopman NMPC: Koopman-based Learning and Nonlinear Model Predictive Control of Control-affine Systems.” arXiv, 2021. doi: 10.48550/ARXIV.2105.08036.

% \bibitem{12} S. L. Brunton, J. L. Proctor, and J. N. Kutz, “Sparse Identification of Nonlinear Dynamics with Control (SINDYc).” arXiv, 2016. doi: 10.48550/ARXIV.1605.06682.

% \bibitem{13} T. A. Howell, B. E. Jackson, and Z. Manchester, “ALTRO: A Fast Solver for Constrained Trajectory Optimization,” in 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2019, pp. 7674–7679. doi: 10.1109/IROS40897.2019.8967788.


% \end{thebibliography}
\end{document}