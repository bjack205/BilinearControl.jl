
@article{Acikmese2013,
  title = {Lossless Convexification of Nonconvex Control Bound and Pointing Constraints of the Soft Landing Optimal Control Problem},
  author = {Acikmese, Behcet and Carson, John M. and Blackmore, Lars},
  date = {2013},
  journaltitle = {IEEE Transactions on Control Systems Technology},
  volume = {21},
  number = {6},
  pages = {2104--2113},
  doi = {10.1109/TCST.2012.2237346},
  abstract = {Planetary soft landing is one of the benchmark problems of optimal control theory and is gaining renewed interest due to the increased focus on the exploration of planets in the solar system, such as Mars. The soft landing problem with all relevant constraints can be posed as a finite-horizon optimal control problem with state and control constraints. The real-time generation of fuel-optimal paths to a prescribed location on a planet's surface is a challenging problem due to the constraints on the fuel, the control inputs, and the states. The main difficulty in solving this constrained problem is the existence of nonconvex constraints on the control input, which are due to a nonzero lower bound on the control input magnitude and a nonconvex constraint on its direction. This paper introduces a convexification of the control constraints that is proven to be lossless; i.e., an optimal solution of the soft landing problem can be obtained via solution of the proposed convex relaxation of the problem. The lossless convexification enables the use of interior point methods of convex optimization to obtain optimal solutions of the original nonconvex optimal control problem. © 1993-2012 IEEE.},
  keywords = {Convex optimization,Convexification,Interior point method algorithms,Optimal control,Planetary soft landing}
}

@inproceedings{Baraff1996,
  title = {Linear-{{Time Dynamics Using Lagrange Multipliers}}},
  booktitle = {{{ACM SIGGRAPH}} 96},
  author = {Baraff, David},
  date = {1996},
  pages = {137--146},
  doi = {10.1145/237170.237226},
  url = {http://portal.acm.org/citation.cfm?doid=237170.237226},
  urldate = {2018-03-28},
  abstract = {Current linear-time simulation methods for articulated figures are based exclusively on reduced-coordinate formulations. This paper describes a general, non-iterative linear-time simulation method based instead on Lagrange multipliers. Lagrange multiplier methods are important for computer graphics applications because they bypass the difficult (and often intractable) problem of parameterizing a system’s degrees of freedom. Given a loop-free set of n equality constraints acting between pairs of bodies, the method takes O(n) time to compute the system’s dynamics. The method does not rely on matrix bandwidth, so no assumptions about the constraints’ topology are needed. Bodies need not be rigid, constraints can be of various dimensions, and unlike reduced-coordinate approaches, nonholonomic (e.g. velocity-dependent) constraints are allowed. An additional set of k one-dimensional constraints which induce loops and/or handle inequalities can be accommodated with cost O(kn). This makes it practical to simulate complicated, closedloop articulated figures with joint-limits and contact at interactive rates. A complete description of a sample implementation is provided in pseudocode.},
  eventtitle = {{{ACM SIGGRAPH}} 96},
  file = {/home/brian/Zotero/storage/QYJYN9QF/Baraff - 1996 - Linear-time dynamics using Lagrange multipliers.pdf}
}

@article{Bjelonic2021,
  title = {Whole-{{Body MPC}} and {{Online Gait Sequence Generation}} for {{Wheeled-Legged Robots}}},
  author = {Bjelonic, Marko and Grandia, Ruben and Harley, Oliver and Galliard, Cla and Zimmermann, Samuel and Hutter, Marco},
  date = {2021},
  journaltitle = {IEEE International Conference on Intelligent Robots and Systems},
  pages = {8388--8395},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {9781665417143},
  doi = {10.1109/IROS51168.2021.9636371},
  abstract = {Our paper proposes a model predictive controller as a single-task formulation that simultaneously optimizes wheel and torso motions. This online joint velocity and ground reaction force optimization integrates a kinodynamic model of a wheeled quadrupedal robot. It defines the single rigid body dynamics along with the robot's kinematics while treating the wheels as moving ground contacts. With this approach, we can accurately capture the robot's rolling constraint and dynamics, enabling automatic discovery of hybrid maneuvers without needless motion heuristics. The formulation's generality through the simultaneous optimization over the robot's whole-body variables allows for a single set of parameters and makes online gait sequence adaptation possible. Aperiodic gait sequences are automatically found through kinematic leg utilities without the need for predefined contact and lift-off timings, reducing the cost of transport by up to 85 \%. Our experiments demonstrate dynamic motions on a quadrupedal robot with non-steerable wheels in challenging indoor and outdoor environments. The paper's findings contribute to evaluating a decomposed, i.e., sequential optimization of wheel and torso motion, and single-task motion planner with a novel quantity, the prediction error, which describes how well a receding horizon planner can predict the robot's future state. To this end, we report an improvement of up to 71 \% using our proposed single-task approach, making fast locomotion feasible and revealing wheeled-legged robots' full potential.}
}

@inproceedings{Bonalli,
  title = {\{\vphantom\}{{GuSTO}}\vphantom\{\}: {{Guaranteed Sequential Trajectory}} Optimization via {{Sequential Convex Programming}}},
  booktitle = {2019 {{International Conference}} on {{Robotics}} and {{Automation}} (\{\vphantom\}{{ICRA}}\vphantom\{\})},
  author = {Bonalli, Riccardo and Cauligi, Abhishek and Bylard, Andrew and Pavone, Marco},
  pages = {6741--6747},
  publisher = {{IEEE}},
  doi = {10.1109/ICRA.2019.8794205},
  url = {https://ieeexplore.ieee.org/document/8794205/},
  abstract = {Sequential Convex Programming (\{SCP\}) has recently seen a surge of interest as a tool for trajectory optimization. Yet, most available methods lack rigorous performance guarantees and are often tailored to specific optimal control setups. In this paper, we present \{GuSTO\} (Guaranteed Sequential Trajectory Optimization), an algorithmic framework to solve trajectory optimization problems for control-affine systems with drift. \{GuSTO\} generalizes earlier \{SCP\}-based methods for trajectory optimization (by addressing, for example, goal region constraints and problems with either fixed or free final time), and enjoys theoretical convergence guarantees in terms of convergence to, at least, a stationary point. The theoretical analysis is further leveraged to devise an accelerated implementation of \{GuSTO\}, which originally infuses ideas from indirect optimal control into an \{SCP\} context. Numerical experiments on a variety of trajectory optimization setups show that \{GuSTO\} generally outperforms current state-of-the-art approaches in terms of success rates, solution quality, and computation times.},
  isbn = {978-1-5386-6027-0},
  file = {/home/brian/Zotero/storage/BJFD9UP5/Bonalli et al. - 2019 - GuSTO Guaranteed Sequential Trajectory optimizati.pdf}
}

@article{Boyd2010,
  title = {Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers},
  author = {Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan},
  date = {2010},
  journaltitle = {Foundations and Trends in Machine Learning},
  volume = {3},
  number = {1},
  pages = {1--122},
  doi = {10.1561/2200000016},
  abstract = {Many problems of recent interest in statistics and machine learning can be posed in the framework of convex optimization. Due to the explosion in size and complexity of modern datasets, it is increasingly important to be able to solve problems with a very large number of features or training examples. As a result, both the decentralized collection or storage of these datasets as well as accompanying distributed solution methods are either necessary or at least highly desirable. In this review, we argue that the alternating direction method of multipliers is well suited to distributed convex optimization, and in particular to large-scale problems arising in statistics, machine learning, and related areas. The method was developed in the 1970s, with roots in the 1950s, and is equivalent or closely related to many other algorithms, such as dual decomposition, the method of multipliers, Douglas-Rachford splitting, Spingarn's method of partial inverses, Dykstra's alternating projections, Bregman iterative algorithms for ℓ1 problems, proximal methods, and thers. After briefly surveying the theory and history of the algorithm, we discuss applications to a wide variety of statistical and machine learning problems of recent interest, including the lasso, sparse logistic regression, basis pursuit, covariance selection, support vector machines, and many others. We also discuss general distributed optimization, extensions to the nonconvex setting, and efficient implementation, including some details on distributed MPI and Hadoop MapReduce implementations. © 2011 S. Boyd, N. Parikh, E. Chu, B. Peleato and J. Eckstein.},
  file = {/home/brian/Zotero/storage/G55UW4LM/admm_distr_stats.pdf}
}

@article{Bruder2021,
  title = {Advantages of {{Bilinear Koopman Realizations}} for the {{Modeling}} and {{Control}} of {{Systems}} with {{Unknown Dynamics}}},
  author = {Bruder, Daniel and Fu, Xun and Vasudevan, Ram},
  date = {2021},
  journaltitle = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {3},
  pages = {4369--4376},
  doi = {10.1109/LRA.2021.3068117},
  abstract = {Nonlinear dynamical systems can be made easier to control by lifting them into the space of observable functions, where their evolution is described by the linear Koopman operator. This letter describes how the Koopman operator can be used to generate approximate linear, bilinear, and nonlinear model realizations from data, and argues in favor of bilinear realizations for characterizing systems with unknown dynamics. Necessary and sufficient conditions for a dynamical system to have a valid linear or bilinear realization over a given set of observable functions are presented and used to show that every control-affine system admits an infinite-dimensional bilinear realization, but does not necessarily admit a linear one. Therefore, approximate bilinear realizations constructed from generic sets of basis functions tend to improve as the number of basis functions increases, whereas approximate linear realizations may not. To demonstrate the advantages of bilinear Koopman realizations for control, a linear, bilinear, and nonlinear Koopman model realization of a simulated robot arm is constructed from data. In a trajectory following task, the bilinear realization exceeds the prediction accuracy of the linear realization and the computational efficiency of the nonlinear realization when incorporated into a model predictive control framework.},
  keywords = {Model learning for control},
  file = {/home/brian/Zotero/storage/ZN9GCDZ3/2010.09961.pdf}
}

@article{Brudigam2021,
  title = {Linear-{{Quadratic Optimal Control}} in {{Maximal Coordinates}}},
  author = {Brüdigam, Jan and Manchester, Zachary},
  date = {2021},
  journaltitle = {Proceedings - IEEE International Conference on Robotics and Automation},
  volume = {2021-May},
  pages = {3546--3552},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {9781728190778},
  doi = {10.1109/ICRA48506.2021.9561871},
  abstract = {The linear-quadratic regulator (LQR) is an efficient control method for linear and linearized systems. Typically, LQR is implemented in minimal coordinates (also called generalized or “joint” coordinates). However, other coordinates are possible and recent research suggests that there may be numerical and control-theoretic advantages when using higher-dimensional non-minimal state parameterizations for dynamical systems. One such parameterization is maximal coordinates, in which each link in a multi-body system is parameterized by its full six degrees of freedom and joints between links are modeled with algebraic constraints. Such constraints can also represent closed kinematic loops or contact with the environment. This paper investigates the difference between minimal- and maximal-coordinate LQR control laws. A case study of applying LQR to a simple pendulum and simulations comparing the basins of attraction of minimal- and maximal-coordinate LQR controllers suggest that maximal-coordinate LQR achieves greater robustness and improved performance compared to minimal-coordinate LQR when applied to nonlinear systems.}
}

@article{Brudigam2021a,
  title = {Linear-{{Time Variational Integrators}} in {{Maximal Coordinates}}},
  author = {Brüdigam, Jan and Manchester, Zachary},
  date = {2021},
  journaltitle = {Springer Proceedings in Advanced Robotics},
  volume = {17},
  pages = {194--209},
  publisher = {{Springer Science and Business Media B.V.}},
  doi = {10.1007/978-3-030-66723-8_12/FIGURES/8},
  url = {https://link.springer.com/chapter/10.1007/978-3-030-66723-8_12},
  abstract = {Most dynamic simulation tools parameterize the configuration of multi-body robotic systems using minimal coordinates, also called generalized or joint coordinates. However, maximal-coordinate approaches have several advantages over minimal-coordinate parameterizations, including native handling of closed kinematic loops and nonholonomic constraints. This paper describes a linear-time variational integrator that is formulated in maximal coordinates. Due to its variational formulation, the algorithm does not suffer from constraint drift and has favorable energy and momentum conservation properties. A sparse matrix factorization technique allows the dynamics of a loop-free articulated mechanism with n links to be computed in O(n) (linear) time. Additional constraints that introduce loops can also be handled by the algorithm without incurring much computational overhead. Experimental results show that our approach offers speed competitive with state-of-the-art minimal-coordinate algorithms while outperforming them in several scenarios, especially when dealing with closed loops and configuration singularities.},
  keywords = {Computer animation and Simulation,Discrete mechanics,Dynamics,Maximal coordinates,Variational integrators}
}

@article{Debnath,
  title = {Invariant {{Extended Kalman Filtering}} for {{Robot Localization}} Using {{IMU}} and {{GPS}}},
  author = {Debnath, Saptadeep and Liang, Anthony and Manda, Gaurav and Tang, Sunbochen and Zhou, Hao},
  url = {https://youtu.be/aILSsw7K2z8},
  abstract = {This paper derives an IMU-GPS-fused inertial navigation observer for a mobile robot using the theory of invariant observer design. One of the main features of invariant observers for invariant systems on Lie groups is that the estimation error is autonomous, hence the observable state variables can be rendered convergent within a domain of attraction that is independent of the system's trajectory. The Invariant Extended Kalman Filter (In-EKF) which is an extension of the Extended Kalman Filter (EKF) is supposed to be more efficient given that the system converges to constant values on a larger set of trajectories as opposed to the equilibrium points that an EKF is based on. This paper explores the implementation of the In-EKF for robot localization and is compared against an implementation of the EKF. The localization is performed on the University of Michigan north campus long-term vision and LIDAR dataset.}
}

@inproceedings{Farshidian2017,
  title = {An Efficient Optimal Planning and Control Framework for Quadrupedal Locomotion},
  booktitle = {2017 \{\vphantom\}{{IEEE}}\vphantom\{\} {{International Conference}} on {{Robotics}} and {{Automation}} (\{\vphantom\}{{ICRA}}\vphantom\{\})},
  author = {Farshidian, Farbod and Neunert, Michael and Winkler, Alexander W and Rey, Gonzalo and Buchli, Jonas},
  date = {2017},
  pages = {93--100},
  doi = {10.1109/ICRA.2017.7989016},
  abstract = {In this paper, we present an efficient Dynamic Programing framework for optimal planning and control of legged robots. First we formulate this problem as an optimal control problem for switched systems. Then we propose a multi-level optimization approach to find the optimal switching times and the optimal continuous control inputs. Through this scheme, the decomposed optimization can potentially be done more efficiently than the combined approach. Finally, we present a continuous-time constrained \{LQR\} algorithm which simultaneously optimizes the feedforward and feedback controller with O(n) time-complexity. In order to validate our approach, we show the performance of our framework on a quadrupedal robot. We choose the Center of Mass dynamics and the full kinematic formulation as the switched system model where the switching times as well as the contact forces and the joint velocities are optimized for different locomotion tasks such as gap crossing, walking and trotting.},
  keywords = {Legged locomotion,Optimal control,Optimization,Planning,Switched systems,Switches},
  file = {/home/brian/Zotero/storage/SMEIMIKA/Farshidian et al. - 2017 - An efficient optimal planning and control framewor.pdf}
}

@legislation{Fasel2021,
  title = {{{SINDy}} with {{Control}}: {{A Tutorial}}},
  date = {2021},
  journaltitle = {Proceedings of the IEEE Conference on Decision and Control},
  volume = {2021-Decem},
  pages = {21},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  doi = {10.1109/CDC45484.2021.9683120},
  url = {https://github.com/urban-fasel/SEIR},
  abstract = {Many dynamical systems of interest are nonlinear, with examples in turbulence, epidemiology, neuroscience, and finance, making them difficult to control using linear approaches. Model predictive control (MPC) is a powerful model-based optimization technique that enables the control of such nonlinear systems with constraints. However, modern systems often lack computationally tractable models, motivating the use of system identification techniques to learn accurate and efficient models for real-time control. In this tutorial article, we review emerging data-driven methods for model discovery and how they are used for nonlinear MPC. In particular, we focus on the sparse identification of nonlinear dynamics (SINDy) algorithm and show how it may be used with MPC on an infectious disease control example. We compare the performance against MPC based on a linear dynamic mode decomposition (DMD) model. Code is provided to run the tutorial examples and may be modified to extend this data-driven control framework to arbitrary nonlinear systems.},
  editora = {Fasel, Urban and Kaiser, Eurika and Kutz, J. Nathan and Brunton, Bingni W. and Brunton, Steven L.},
  editoratype = {collaborator},
  isbn = {9781665436595},
  keywords = {data-driven models,DMD,ma-chine learning,machine learning,Model predictive control,SINDy,system identification}
}

@article{Folkestad2020,
  title = {Episodic {{Koopman Learning}} of {{Nonlinear Robot Dynamics}} with {{Application}} to {{Fast Multirotor Landing}}},
  author = {Folkestad, Carl and Pastor, Daniel and Burdick, Joel W.},
  date = {2020-05},
  journaltitle = {Proceedings - IEEE International Conference on Robotics and Automation},
  pages = {9216--9222},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {9781728173955},
  doi = {10.1109/ICRA40945.2020.9197510},
  abstract = {This paper presents a novel episodic method to learn a robot's nonlinear dynamics model and an increasingly optimal control sequence for a set of tasks. The method is based on the Koopman operator approach to nonlinear dynamical systems analysis, which models the flow of observables in a function space, rather than a flow in a state space. Practically, this method estimates a nonlinear diffeomorphism that lifts the dynamics to a higher dimensional space where they are linear. Efficient Model Predictive Control methods can then be applied to the lifted model. This approach allows for real time implementation in on-board hardware, with rigorous incorporation of both input and state constraints during learning. We demonstrate the method in a real-time implementation of fast multirotor landing, where the nonlinear ground effect is learned and used to improve landing speed and quality.}
}

@inproceedings{Folkestad2021,
  title = {Koopman {{NMPC}}: {{Koopman-based Learning}} and {{Nonlinear Model Predictive Control}} of {{Control-affine Systems}}},
  booktitle = {Proceedings - {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Folkestad, Carl and Burdick, Joel W.},
  date = {2021},
  volume = {2021-May},
  pages = {7350--7356},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  doi = {10.1109/ICRA48506.2021.9562002},
  abstract = {Koopman-based learning methods can potentially be practical and powerful tools for dynamical robotic systems. However, common methods to construct Koopman representations seek to learn lifted linear models that cannot capture nonlinear actuation effects inherent in many robotic systems. This paper presents a learning and control methodology that is a first step towards overcoming this limitation. Using the Koopman canonical transform, control-affine dynamics can be expressed by a lifted bilinear model. The learned model is used for nonlinear model predictive control (NMPC) design where the bilinear structure can be exploited to improve computational efficiency. The benefits for control-affine dynamics compared to existing Koopman-based methods are highlighted through an example of a simulated planar quadrotor. Prediction error is greatly reduced and closed loop performance similar to NMPC with full model knowledge is achieved.},
  isbn = {978-1-72819-077-8}
}

@unpublished{Folkestad2021a,
  title = {Quadrotor {{Trajectory Tracking}} with {{Learned Dynamics}}: {{Joint Koopman-based Learning}} of {{System Models}} and {{Function Dictionaries}}},
  shorttitle = {Quadrotor {{Trajectory Tracking}} with {{Learned Dynamics}}},
  author = {Folkestad, Carl and Wei, Skylar X. and Burdick, Joel W.},
  date = {2021-10-19},
  number = {arXiv:2110.10341},
  eprint = {2110.10341},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2110.10341},
  urldate = {2022-06-13},
  abstract = {Nonlinear dynamical effects are crucial to the operation of many agile robotic systems. Koopman-based model learning methods can capture these nonlinear dynamical system effects in higher dimensional lifted bilinear models that are amenable to optimal control. However, standard methods that lift the system state using a fixed function dictionary before model learning result in high dimensional models that are intractable for real time control. This paper presents a novel method that jointly learns a function dictionary and lifted bilinear model purely from data by incorporating the Koopman model in a neural network architecture. Nonlinear MPC design utilizing the learned model can be performed readily. We experimentally realized this method on a multirotor drone for agile trajectory tracking at low altitudes where the aerodynamic ground effect influences the system's behavior. Experimental results demonstrate that the learning-based controller achieves similar performance as a nonlinear MPC based on a nominal dynamics model in medium altitude. However, our learning-based system can reliably track trajectories in near-ground flight regimes while the nominal controller crashes due to unmodeled dynamical effects that are captured by our method.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/home/brian/Zotero/storage/BLPDUBMD/Folkestad et al. - 2021 - Quadrotor Trajectory Tracking with Learned Dynamic.pdf;/home/brian/Zotero/storage/9C9LBAWY/2110.html}
}

@article{Fong2011,
  title = {{{LSMR}}: {{An Iterative Algorithm}} for {{Sparse Least-Squares Problems}}},
  shorttitle = {{{LSMR}}},
  author = {Fong, David Chin-Lung and Saunders, Michael},
  date = {2011-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {33},
  number = {5},
  pages = {2950--2971},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/10079687X},
  url = {https://epubs.siam.org/doi/abs/10.1137/10079687X},
  urldate = {2022-06-14},
  abstract = {An iterative method LSMR is presented for solving linear systems \$Ax=b\$ and least-squares problems \$\textbackslash min \textbackslash |Ax-b\textbackslash |\_2\$, with A being sparse or a fast linear operator. LSMR is based on the Golub–Kahan bidiagonalization process. It is analytically equivalent to the MINRES method applied to the normal equation \$A\^T\textbackslash! Ax = A\^T\textbackslash! b\$, so that the quantities \$\textbackslash |A\^T\textbackslash! r\_k\textbackslash |\$ are monotonically decreasing (where \$r\_k = b - Ax\_k\$ is the residual for the current iterate \$x\_k\$). We observe in practice that \$\textbackslash |r\_k\textbackslash |\$ also decreases monotonically, so that compared to LSQR (for which only \$\textbackslash |r\_k\textbackslash |\$ is monotonic) it is safer to terminate LSMR early. We also report some experiments with reorthogonalization.},
  keywords = {15A06,65F10,65F20,65F22,65F25,65F35,65F50,93E24,conjugate-gradient method,Golub–Kahan process,iterative method,Krylov subspace method,least-squares problem,LSQR,minimum-residual method,MINRES,sparse matrix},
  file = {/home/brian/Zotero/storage/XUMW7ZDS/Fong and Saunders - 2011 - LSMR An Iterative Algorithm for Sparse Least-Squa.pdf}
}

@article{Garstka2021,
  title = {{{COSMO}}: {{A Conic Operator Splitting Method}} for {{Convex Conic Problems}}},
  author = {Garstka, Michael and Cannon, Mark and Goulart, Paul},
  date = {2021-09},
  journaltitle = {Journal of Optimization Theory and Applications},
  volume = {190},
  number = {3},
  pages = {779--810},
  publisher = {{Springer}},
  doi = {10.1007/S10957-021-01896-X/TABLES/7},
  url = {https://link.springer.com/article/10.1007/s10957-021-01896-x},
  abstract = {This paper describes the conic operator splitting method (COSMO) solver, an operator splitting algorithm and associated software package for convex optimisation problems with quadratic objective function and conic constraints. At each step, the algorithm alternates between solving a quasi-definite linear system with a constant coefficient matrix and a projection onto convex sets. The low per-iteration computational cost makes the method particularly efficient for large problems, e.g. semidefinite programs that arise in portfolio optimisation, graph theory, and robust control. Moreover, the solver uses chordal decomposition techniques and a new clique merging algorithm to effectively exploit sparsity in large, structured semidefinite programs. Numerical comparisons with other state-of-the-art solvers for a variety of benchmark problems show the effectiveness of our approach. Our Julia implementation is open source, designed to be extended and customised by the user, and is integrated into the Julia optimisation ecosystem.},
  keywords = {ADMM,Chordal decomposition,Clique merging,Conic programming}
}

@article{Hargraves,
  title = {Direct Trajectory Optimization Using Nonlinear Programming and Collocation},
  author = {Hargraves, Charles R and Paris, Stephen W},
  volume = {10},
  number = {4},
  pages = {338--342}
}

@article{Hoeller2020,
  title = {Deep {{Value Model Predictive Control}}},
  author = {Hoeller, David ; and Farshidian, Farbod ; and Hutter, Marco and Farshidian, Farbod and Hoeller, David},
  date = {2020},
  journaltitle = {Proceedings of the Conference on Robot Learning},
  volume = {100},
  pages = {990--1004},
  publisher = {{PMLR}},
  doi = {10.3929/ETHZ-B-000368961},
  url = {https://doi.org/10.3929/ethz-b-000368961},
  abstract = {Permanent link: https://doi. Abstract: In this paper, we introduce an actor-critic algorithm called Deep Value Model Predictive Control (DMPC), which combines model-based trajectory optimization with value function estimation. The DMPC actor is a Model Predictive Control (MPC) optimizer with an objective function defined in terms of a value function estimated by the critic. We show that our MPC actor is an importance sampler, which minimizes an upper bound of the cross-entropy to the state distribution of the optimal sampling policy. In our experiments with a Ballbot system, we show that our algorithm can work with sparse and binary reward signals to efficiently solve obstacle avoidance and target reaching tasks. Compared to previous work, we show that including the value function in the running cost of the trajectory optimizer speeds up the convergence. We also discuss the necessary strategies to robustify the algorithm in practice.},
  keywords = {Model Predictive Control (MPC),REINFORCEMENT LEARNING (ARTIFICIAL INTELLIGENCE),ROBOTICS,Value Function Learning}
}

@article{Hofmann2006,
  title = {Support {{Vector Machines-Kernels}} and the {{Kernel Trick An}} Elaboration for the {{Hauptseminar}} "{{Reading Club}}: {{Support Vector Machines}}"},
  author = {Hofmann, Martin},
  date = {2006}
}

@article{Howell2019,
  title = {{{ALTRO}}: {{A Fast Solver}} for {{Constrained Trajectory Optimization}}},
  author = {Howell, Taylor A. and Jackson, Brian E. and Manchester, Zachary},
  date = {2019-11},
  journaltitle = {IEEE International Conference on Intelligent Robots and Systems},
  pages = {7674--7679},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {9781728140049},
  doi = {10.1109/IROS40897.2019.8967788},
  abstract = {Trajectory optimization is a widely used tool for robot motion planning and control. Existing solvers for these problems either rely on off-the-shelf nonlinear programming solvers that are numerically robust and capable of handling arbitrary constraints, but tend to be slow because they are general purpose; or they use custom numerical methods that take advantage of the problem structure to be fast, but often lack robustness and have limited or no ability to reason about constraints. This paper presents ALTRO (Augmented Lagrangian TRajectory optimizer), a solver for constrained trajectory optimization problems that handles general nonlinear state and input constraints and offers fast convergence and numerical robustness thanks to careful exploitation of problem structure. We demonstrate its performance on a set of benchmark motion-planning problems and offer comparisons to the standard direct collocation method with large-scale sequential quadratic programming and interior-point solvers.}
}

@article{Howell2022,
  title = {Dojo: {{A Differentiable Simulator}} for {{Robotics}}},
  author = {Howell, Taylor A and Le Cleac', Simon and Kolter, J Zico and Schwager, Mac and Manchester, Zachary},
  date = {2022},
  abstract = {We present a differentiable rigid-body-dynamics simulator for robotics that prioritizes physical accuracy and differentiability: Dojo. The simulator utilizes an expressive maximal-coordinates representation, achieves stable simulation at low sample rates, and conserves energy and momentum by employing a variational integrator. A nonlinear complementarity problem, with nonlinear friction cones, models hard contact and is reliably solved using a custom primal-dual interior-point method. The implicit-function theorem enables efficient differentiation of an intermediate relaxed problem and computes smooth gradients from the contact model. We demonstrate the usefulness of the simulator and its gradients through a number of examples including: simulation, trajectory optimization, reinforcement learning, and system identification.}
}

@article{Jackson2021,
  title = {{{ALTRO-C}}: {{A Fast Solver}} for {{Conic Model-Predictive Control}}; {{ALTRO-C}}: {{A Fast Solver}} for {{Conic Model-Predictive Control}}},
  author = {Jackson, Brian E and Punnoose, Tarun and Neamati, Daniel and Tracy, Kevin and Jitosho, Rianna and Manchester, Zachary},
  date = {2021},
  journaltitle = {2021 IEEE International Conference on Robotics and Automation (ICRA)},
  issn = {9781728190778},
  doi = {10.1109/ICRA48506.2021.9561438},
  url = {https://github.com/},
  abstract = {Model-predictive control (MPC) is an increasingly popular method for controlling complex robotic systems in which optimal control problems are solved on board the robot at real-time rates. However, successful application of MPC depends critically on the performance of the algorithms used to solve the underlying optimization problems. An ideal solver should both leverage the structure of the MPC problem and support efficient "warm starting" so that information from previous solutions can be recycled to speed convergence. We present ALTRO-C, a high-performance solver with both of these properties that utilizes an augmented Lagrangian method to handle general convex conic constraints. We demonstrate the new solver's superior performance against several existing state-of-the-art solvers on a variety of benchmark control problems formulated as both quadratic and second-order cone programs.}
}

@article{Jacobson,
  title = {Differential Dynamic Programming},
  author = {Jacobson, David H and Mayne, David Q}
}

@article{Kaiser2018,
  title = {Sparse Identification of Nonlinear Dynamics for Model Predictive Control in the Low-Data Limit},
  author = {Kaiser, E. and Kutz, J. N. and Brunton, S. L.},
  date = {2018-11},
  journaltitle = {Proceedings of the Royal Society A},
  volume = {474},
  number = {2219},
  publisher = {{The Royal Society Publishing}},
  doi = {10.1098/RSPA.2018.0335},
  url = {https://royalsocietypublishing.org/doi/full/10.1098/rspa.2018.0335},
  abstract = {Data-driven discovery of dynamics via machine learning is pushing the frontiers of modelling and control efforts, providing a tremendous opportunity to extend the reach of model predictive control ...},
  keywords = {control theory,machine learning,model predictive control,nonlinear dynamics,sparse identification of nonlinear dynamics,sparse identification of nonlineardynamics,system identification}
}

@article{Karnchanachari2020,
  title = {Practical {{Reinforcement Learning For MPC}}: {{Learning}} from Sparse Objectives in under an Hour on a Real Robot},
  author = {Karnchanachari, Napat and Valls, Miguel I and David Hoeller, Sevensensech and Hutter, Marco},
  date = {2020},
  journaltitle = {Proceedings of Machine Learning Research},
  pages = {1--14},
  publisher = {{OpenReview}},
  doi = {10.3929/ETHZ-B-000404690},
  url = {https://doi.org/10.3929/ethz-b-000404690},
  abstract = {Model Predictive Control (MPC) is a powerful control technique that handles constraints, takes the system's dynamics into account, and optimizes for a given cost function. In practice, however, it often requires an expert to craft and tune this cost function and find trade-offs between different state penalties to satisfy simple high level objectives. In this paper, we use Reinforcement Learning and in particular value learning to approximate the value function given only high level objectives , which can be sparse and binary. Building upon previous works, we present improvements that allowed us to successfully deploy the method on a real world unmanned ground vehicle. Our experiments show that our method can learn the cost function from scratch and without human intervention , while reaching a performance level similar to that of an expert-tuned MPC. We perform a quantitative comparison of these methods with standard MPC approaches both in simulation and on the real robot. A demonstration of our method can be seen in the video: https://youtu.be/PJB8XdXBP\_M},
  keywords = {Autonomous Robots,Model Predictive Control,Reinforcement Learning}
}

@article{Korda2018,
  title = {Linear Predictors for Nonlinear Dynamical Systems: {{Koopman}} Operator Meets Model Predictive Control},
  author = {Korda, Milan and Mezić, Igor},
  date = {2018},
  journaltitle = {Automatica},
  volume = {93},
  pages = {149--160},
  doi = {10.1016/j.automatica.2018.03.046},
  url = {https://doi.org/10.1016/j.automatica.2018.03.046},
  abstract = {This paper presents a class of linear predictors for nonlinear controlled dynamical systems. The basic idea is to lift (or embed) the nonlinear dynamics into a higher dimensional space where its evolution is approximately linear. In an uncontrolled setting, this procedure amounts to numerical approximations of the Koopman operator associated to the nonlinear dynamics. In this work, we extend the Koopman operator to controlled dynamical systems and apply the Extended Dynamic Mode Decomposition (EDMD) to compute a finite-dimensional approximation of the operator in such a way that this approximation has the form of a linear controlled dynamical system. In numerical examples, the linear predictors obtained in this way exhibit a performance superior to existing linear predictors such as those based on local linearization or the so called Carleman linearization. Importantly, the procedure to construct these linear predictors is completely data-driven and extremely simple-it boils down to a nonlinear transformation of the data (the lifting) and a linear least squares problem in the lifted space that can be readily solved for large data sets. These linear predictors can be readily used to design controllers for the nonlinear dynamical system using linear controller design methodologies. We focus in particular on model predictive control (MPC) and show that MPC controllers designed in this way enjoy computational complexity of the underlying optimization problem comparable to that of MPC for a linear dynamical system with the same number of control inputs and the same dimension of the state-space. Importantly, linear inequality constraints on the state and control inputs as well as nonlinear constraints on the state can be imposed in a linear fashion in the proposed MPC scheme. Similarly, cost functions nonlinear in the state variable can be handled in a linear fashion. We treat both the full-state measurement case and the input-output case, as well as systems with disturbances/noise. Numerical examples demonstrate the approach. 1},
  keywords = {Data-driven control design,Koopman operator,Lifting,Model predictive control,Optimal control}
}

@article{Kuindersma2014,
  title = {An Efficiently Solvable Quadratic Program for Stabilizing Dynamic Locomotion},
  author = {Kuindersma, Scott and Permenter, Frank and Tedrake, Russ},
  date = {2014-09},
  journaltitle = {Proceedings - IEEE International Conference on Robotics and Automation},
  pages = {2589--2594},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {9781479936854},
  doi = {10.1109/ICRA.2014.6907230},
  abstract = {We describe a whole-body dynamic walking controller implemented as a convex quadratic program. The controller solves an optimal control problem using an approximate value function derived from a simple walking model while respecting the dynamic, input, and contact constraints of the full robot dynamics. By exploiting sparsity and temporal structure in the optimization with a custom active-set algorithm, we surpass the performance of the best available off-the-shelf solvers and achieve 1kHz control rates for a 34-DOF humanoid. We describe applications to balancing and walking tasks using the simulated Atlas robot in the DARPA Virtual Robotics Challenge.}
}

@article{Li2021,
  title = {Reinforcement {{Learning}} for {{Robust Parameterized Locomotion Control}} of {{Bipedal Robots}}},
  author = {Li, Zhongyu and Cheng, Xuxin and Peng, Xue Bin and Abbeel, Pieter and Levine, Sergey and Berseth, Glen and Sreenath, Koushil},
  date = {2021},
  journaltitle = {Proceedings - IEEE International Conference on Robotics and Automation},
  volume = {2021-May},
  pages = {2811--2817},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {9781728190778},
  doi = {10.1109/ICRA48506.2021.9560769},
  abstract = {Developing robust walking controllers for bipedal robots is a challenging endeavor. Traditional model-based locomotion controllers require simplifying assumptions and careful modelling; any small errors can result in unstable control. To address these challenges for bipedal locomotion, we present a model-free reinforcement learning framework for training robust locomotion policies in simulation, which can then be transferred to a real bipedal Cassie robot. To facilitate sim-to-real transfer, domain randomization is used to encourage the policies to learn behaviors that are robust across variations in system dynamics. The learned policies enable Cassie to perform a set of diverse and dynamic behaviors, while also being more robust than traditional controllers and prior learning-based methods that use residual control. We demonstrate this on versatile walking behaviors such as tracking a target walking velocity, walking height, and turning yaw. (Video).}
}

@article{Meduri2022,
  title = {{{BiConMP}}: {{A Nonlinear Model Predictive Control Framework}} for {{Whole Body Motion Planning}}},
  author = {Meduri, Avadesh and Shah, Paarth and Viereck, Julian and Khadiv, Majid and Havoutis, Ioannis and Righetti, Ludovic},
  date = {2022-01},
  doi = {10.48550/arxiv.2201.07601},
  url = {https://arxiv.org/abs/2201.07601v1},
  abstract = {Online planning of whole-body motions for legged robots is challenging due to the inherent nonlinearity in the robot dynamics. In this work, we propose a nonlinear MPC framework, the BiConMP which can generate whole body trajectories online by efficiently exploiting the structure of the robot dynamics. BiConMP is used to generate various cyclic gaits on a real quadruped robot and its performance is evaluated on different terrain, countering unforeseen pushes and transitioning online between different gaits. Further, the ability of BiConMP to generate non-trivial acyclic whole-body dynamic motions on the robot is presented. Finally, an extensive empirical analysis on the effects of planning horizon and frequency on the nonlinear MPC framework is reported and discussed.}
}

@article{Narasingam2022,
  title = {Data-Driven Feedback Stabilization of Nonlinear Systems: {{Koopman-based}} Model Predictive Control},
  author = {Narasingam, Abhinav and Sang, Joseph and Kwon, Il},
  date = {2022},
  journaltitle = {International Journal of Control},
  pages = {1--12},
  publisher = {{Taylor \& Francis}},
  abstract = {In this work, a predictive control framework is presented for feedback stabilization of nonlinear systems. To achieve this, we integrate Koopman operator theory with Lyapunov-based model predictive control (LMPC). The main idea is to transform nonlinear dynamics from state-space to function space using Koopman eigenfunctions-for control affine systems this results in a bilinear model in the (lifted) function space. Then, a predictive controller is formulated in Koopman eigenfunction coordinates which uses an auxiliary Control Lyapunov Function (CLF) based bounded controller as a constraint to ensure stability of the Koopman system in the function space. Provided there exists a continuously differentiable inverse mapping between the original state-space and (lifted) function space, we show that the designed controller is capable of translating the feedback stabiliz-ability of the Koopman bilinear system to the original nonlinear system. Remarkably, the feedback control design proposed in this work remains completely data-driven and does not require any explicit knowledge of the original system. Furthermore, due to the bilinear structure of the Koopman model, seeking a CLF is no longer a bottleneck for LMPC. Benchmark numerical examples demonstrate the utility of the proposed feedback control design.},
  keywords = {con-trol Lyapunov functions,feedback stabilization,Index Terms-Koopman operator,model predictive control}
}

@article{Paige1982,
  title = {{{LSQR}}: {{An Algorithm}} for {{Sparse Linear Equations}} and {{Sparse Least Squares}}},
  shorttitle = {{{LSQR}}},
  author = {Paige, Christopher C. and Saunders, Michael A.},
  date = {1982-03},
  journaltitle = {ACM Transactions on Mathematical Software},
  shortjournal = {ACM Trans. Math. Softw.},
  volume = {8},
  number = {1},
  pages = {43--71},
  issn = {0098-3500, 1557-7295},
  doi = {10.1145/355984.355989},
  url = {https://dl.acm.org/doi/10.1145/355984.355989},
  urldate = {2022-06-14},
  langid = {english},
  file = {/home/brian/Zotero/storage/GD52P95G/Paige and Saunders - 1982 - LSQR An Algorithm for Sparse Linear Equations and.pdf}
}

@article{Parikh2014,
  title = {Proximal {{Algorithms}}},
  author = {Parikh, Neal},
  date = {2014},
  journaltitle = {Foundations and Trends® in Optimization},
  volume = {1},
  number = {3},
  pages = {127--239},
  doi = {10.1561/2400000003},
  abstract = {Thismonograph is about a class of optimization algorithms called prox- imal algorithms.Much like Newton’s method is a standard tool for solv- ing unconstrained smooth optimization problems of modest size, proxi- mal algorithms can be viewed as an analogous tool for nonsmooth, con- strained, large-scale, or distributed versions of these problems. They are very generally applicable, but are especially well-suited to problems of substantial recent interest involving large or high-dimensional datasets. Proximal methods sit at a higher level of abstraction than classical al- gorithms like Newton’s method: the base operation is evaluating the proximal operator of a function, which itself involves solving a small convex optimization problem. These subproblems, which generalize the problem of projecting a point onto a convex set, often admit closed- form solutions or can be solved very quickly with standard or simple specialized methods. Here, we discuss the many different interpreta- tions of proximal operators and algorithms, describe their connections to many other topics in optimization and applied mathematics, survey some popular algorithms, and provide a large number of examples of proximal operators that commonly arise in practice.},
  file = {/home/brian/Zotero/storage/EXLGFW46/prox_algs.pdf}
}

@article{Peitz2020,
  title = {Data-Driven Model Predictive Control Using Interpolated Koopman Generators},
  author = {Peitz, Sebastian and Otto, Samuel E. and Rowley, Clarence W.},
  date = {2020},
  journaltitle = {SIAM Journal on Applied Dynamical Systems},
  volume = {19},
  number = {3},
  pages = {2162--2193},
  publisher = {{Society for Industrial and Applied Mathematics Publications}},
  doi = {10.1137/20M1325678},
  url = {https://doi.org/10.1137/20M1325678},
  abstract = {In recent years, the success of the Koopman operator in dynamical systems analysis has also fueled the development of Koopman operator-based control frameworks. In order to preserve the relatively low data requirements for an approximation via dynamic mode decomposition, a quantization approach was recently proposed in [S. Peitz and S. Klus, Automatica J. IFAC, 106 (2019), pp. 184- 191]. This way, control of nonlinear dynamical systems can be realized by means of switched systems techniques, using only a finite set of autonomous Koopman operator-based reduced models. These individual systems can be approximated very efficiently from data. The main idea is to transform a control system into a set of autonomous systems for which the optimal switching sequence has to be computed. In this article, we extend these results to continuous control inputs using relaxation. This way, we combine the advantages of the data efficiency of approximating a finite set of autonomous systems with continuous controls, as the data requirements increase only linearly with the input dimension. We show that when using the Koopman generator, this relaxation-realized by linear interpolation between two operators-does not introduce any error for control affine systems. This allows us to control high-dimensional nonlinear systems using bilinear, low-dimensional surrogate models. The efficiency of the proposed approach is demonstrated using several examples with increasing complexity, from the Duffing oscillator to the chaotic fluidic pinball.},
  keywords = {Dynamic mode decomposition,Koopman operator,Model predictive control,optimal control,Optimal control,reduced order modeling,Reduced order modeling}
}

@article{Proctor2018,
  title = {Generalizing Koopman Theory to Allow for Inputs and Control},
  author = {Proctor, Joshua L. and Brunton, Steven L. and Nathan Kutz, J.},
  date = {2018},
  journaltitle = {SIAM Journal on Applied Dynamical Systems},
  volume = {17},
  number = {1},
  pages = {909--930},
  publisher = {{Society for Industrial and Applied Mathematics Publications}},
  doi = {10.1137/16M1062296},
  url = {http://www.siam.org/journals/siads/17-1/M106229.html},
  abstract = {We develop a new generalization of Koopman operator theory that incorporates the effects of inputs and control. Koopman spectral analysis is a theoretical tool for the analysis of nonlinear dynamical systems. Moreover, Koopman is intimately connected to dynamic mode decomposition (DMD), a method that discovers coherent, spatio-temporal modes from data, connects local-linear analysis to nonlinear operator theory, and importantly creates an equation-free architecture for the study of complex systems. For actuated systems, standard Koopman analysis and DMD are incapable of producing input-output models; moreover, the dynamics and the modes will be corrupted by external forcing. Our new theoretical developments extend Koopman operator theory to allow for systems with nonlinear input-output characteristics. We show how this generalization is rigorously connected to a recent development called dynamic mode decomposition with control. We demonstrate this new theory on nonlinear dynamical systems, including a standard susceptible-infectious-recovered model with relevance to the analysis of infectious disease data with mass vaccination (actuation).},
  keywords = {DMD,DMDc,input-output,Input-output,Koopman,Spatio-temporal,spatio-temporal AMS subject classifications 65P99}
}

@article{Rodriguez2018,
  title = {Benchmarking {{ADMM}} in Nonconvex {{NLPs}}},
  author = {Rodriguez, Jose S. and Nicholson, Bethany and Laird, Carl and Zavala, Victor M.},
  date = {2018-11},
  journaltitle = {Computers \& Chemical Engineering},
  volume = {119},
  pages = {315--325},
  publisher = {{Pergamon}},
  doi = {10.1016/J.COMPCHEMENG.2018.08.036},
  abstract = {We study connections between the alternating direction method of multipliers (ADMM), the classical method of multipliers (MM), and progressive hedging (PH). The connections are used to derive benchmark metrics and strategies to monitor and accelerate convergence and to help explain why ADMM and PH are capable of solving complex nonconvex NLPs. Specifically, we observe that ADMM is an inexact version of MM and approaches its performance when multiple coordination steps are performed. In addition, we use the observation that PH is a specialization of ADMM and borrow Lyapunov function and primal-dual feasibility metrics used in ADMM to explain why PH is capable of solving nonconvex NLPs. This analysis also highlights that specialized PH schemes can be derived to tackle a wider range of stochastic programs and even other problem classes. Our exposition is tutorial in nature and seeks to to motivate algorithmic improvements and new decomposition strategies},
  keywords = {ADMM,Augmented Lagrangian,Coordination,Decomposition,Large-scale,NLP}
}

@report{Royer2018,
  title = {A {{Newton-CG Algorithm}} with {{Complexity Guarantees}} for {{Smooth Unconstrained Optimization}}},
  author = {Royer, Clément W and O'neill, Michael and Wright, Stephen J and Royer, C W and O'neill, M and Wright, S J},
  date = {2018},
  abstract = {We consider minimization of a smooth nonconvex objective function using an iterative algorithm based on Newton's method and the linear conjugate gradient algorithm, with explicit detection and use of negative curvature directions for the Hessian of the objective function. The algorithm tracks Newton-conjugate gradient procedures developed in the 1980s closely, but includes enhancements that allow worst-case complexity results to be proved for convergence to points that satisfy approximate first-order and second-order optimality conditions. The complexity results match the best known results in the literature for second-order methods.},
  keywords = {Classification,Mathematics,smooth nonconvex optimization ·,Subject}
}

@article{Subosits2019,
  title = {From the Racetrack to the Road: {{Real-time}} Trajectory Replanning for Autonomous Driving},
  author = {Subosits, John K. and Gerdes, J. Christian},
  date = {2019-06},
  journaltitle = {IEEE Transactions on Intelligent Vehicles},
  volume = {4},
  number = {2},
  pages = {309--320},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  doi = {10.1109/TIV.2019.2904390},
  abstract = {In emergency situations, autonomous vehicles will be forced to operate at their friction limits in order to avoid collisions. In these scenarios, coordinating the planning of the vehicle's path and speed gives the vehicle the best chance of avoiding an obstacle. Fast reaction time is also important in an emergency, but approaches to the trajectory planning problem based on nonlinear optimization are computationally expensive. This paper presents a new scheme that simultaneously modifies the desired path and speed profile for a vehicle in response to the appearance of an obstacle, significant tracking error, or other environmental change. By formulating the trajectory optimization problem as a quadratically constrained quadratic program, solution times of less than 20 ms are possible even with a 10-s planning horizon. A simplified point mass model is used to describe the vehicle's motion, but the incorporation of longitudinal weight transfer and road topography means that the vehicle's acceleration limits are modeled more accurately than in comparable approaches. Experimental data from an autonomous vehicle in two scenarios demonstrate how the trajectory planner enables the vehicle to avoid an obstacle even when the obstacle appears suddenly and the vehicle is already operating near the friction limits.},
  keywords = {Autonomous vehicles,intelligent vehicles,quadratic programming,trajectory optimization,vehicle dynamics,vehicle safety}
}

@article{Suh2020,
  title = {The {{Surprising Effectiveness}} of {{Linear Models}} for {{Visual Foresight}} in {{Object Pile Manipulation}}},
  author = {Suh, H. J.Terry and Tedrake, Russ},
  date = {2020-02},
  journaltitle = {Springer Proceedings in Advanced Robotics},
  volume = {17},
  pages = {347--363},
  publisher = {{Springer Science and Business Media B.V.}},
  doi = {10.48550/arxiv.2002.09093},
  url = {https://arxiv.org/abs/2002.09093v3},
  abstract = {In this paper, we tackle the problem of pushing piles of small objects into a desired target set using visual feedback. Unlike conventional single-object manipulation pipelines, which estimate the state of the system parametrized by pose, the underlying physical state of this system is difficult to observe from images. Thus, we take the approach of reasoning directly in the space of images, and acquire the dynamics of visual measurements in order to synthesize a visual-feedback policy. We present a simple controller using an image-space Lyapunov function, and evaluate the closed-loop performance using three different class of models for image prediction: deep-learning-based models for image-to-image translation, an object-centric model obtained from treating each pixel as a particle, and a switched-linear system where an action-dependent linear map is used. Through results in simulation and experiment, we show that for this task, a linear model works surprisingly well -- achieving better prediction error, downstream task performance, and generalization to new environments than the deep models we trained on the same amount of data. We believe these results provide an interesting example in the spectrum of models that are most useful for vision-based feedback in manipulation, considering both the quality of visual prediction, as well as compatibility with rigorous methods for control design and analysis. Project site: https://sites.google.com/view/linear-visual-foresight/home},
  keywords = {Deformable Objects,Image Prediction,Manipulation,Piles of Objects,Vision-based Control,Visual Foresight}
}

@book{Surana2016,
  title = {Koopman Operator Based Observer Synthesis for Control-Affine Nonlinear Systems; {{Koopman}} Operator Based Observer Synthesis for Control-Affine Nonlinear Systems},
  author = {Surana, Amit},
  date = {2016},
  doi = {10.1109/CDC.2016.7799268},
  abstract = {We propose a new observer form based on Koop-man operator theoretic framework for input-output nonlinear systems with control affine inputs. Based on this observer form, we describe an observer synthesis framework which exploits estimation techniques developed for Lipschitz systems and bilinear systems. We also formulate nonlinear observability rank condition in terms of the Koopman observer form, and numerically illustrate the benefits of the proposed framework.},
  isbn = {978-1-5090-1837-6}
}

@article{Teng2022,
  title = {An {{Error-State Model Predictive Control}} on {{Connected Matrix Lie Groups}} for {{Legged Robot Control}}},
  author = {Teng, Sangli and Chen, Dianhao and Clark, William and Ghaffari, Maani},
  date = {2022-03},
  doi = {10.48550/arxiv.2203.08728},
  url = {https://arxiv.org/abs/2203.08728v1},
  abstract = {This paper reports on a new error-state Model Predictive Control (MPC) approach on connected matrix Lie groups for robot control. The linearized tracking error dynamics and the linearized equations of motion are derived in the Lie algebra. Moreover, given an initial condition, the linearized tracking error dynamics and equations of motion are globally valid and evolve independently of the system trajectory. By exploiting the symmetry of the problem, the proposed approach shows faster convergence of rotation and position simultaneously than the state-of-the-art geometric variational MPC based on variational-based linearization. Numerical simulation on tracking control of a fully-actuated 3D rigid body dynamics confirms the benefits of the proposed approach compared to the baselines. Furthermore, the proposed MPC is also verified in pose control and locomotion experiments on a quadrupedal robot MIT Mini Cheetah.}
}

@article{Williams2015,
  title = {A {{Data}}–{{Driven Approximation}} of the {{Koopman Operator}}: {{Extending Dynamic Mode Decomposition}}},
  author = {Williams, Matthew O. and Kevrekidis, Ioannis G. and Rowley, Clarence W.},
  date = {2015-12},
  journaltitle = {Journal of Nonlinear Science},
  volume = {25},
  number = {6},
  pages = {1307--1346},
  publisher = {{Springer New York LLC}},
  doi = {10.1007/S00332-015-9258-5/FIGURES/14},
  url = {https://link.springer.com/article/10.1007/s00332-015-9258-5},
  abstract = {The Koopman operator is a linear but infinite-dimensional operator that governs the evolution of scalar observables defined on the state space of an autonomous dynamical system and is a powerful tool for the analysis and decomposition of nonlinear dynamical systems. In this manuscript, we present a data-driven method for approximating the leading eigenvalues, eigenfunctions, and modes of the Koopman operator. The method requires a data set of snapshot pairs and a dictionary of scalar observables, but does not require explicit governing equations or interaction with a “black box” integrator. We will show that this approach is, in effect, an extension of dynamic mode decomposition (DMD), which has been used to approximate the Koopman eigenvalues and modes. Furthermore, if the data provided to the method are generated by a Markov process instead of a deterministic dynamical system, the algorithm approximates the eigenfunctions of the Kolmogorov backward equation, which could be considered as the “stochastic Koopman operator” (Mezic in Nonlinear Dynamics 41(1–3): 309–325,~2005). Finally, four illustrative examples are presented: two that highlight the quantitative performance of the method when presented with either deterministic or stochastic data and two that show potential applications of the Koopman eigenfunctions.},
  keywords = {Data mining,Koopman spectral analysis,Reduced order models,Set oriented methods,Spectral methods}
}

@article{Xu,
  title = {Adaptive {{ADMM}} with {{Spectral Penalty Parameter Selection}}},
  author = {Xu, Zheng and Figueiredo, Mário A T and Goldstein, Tom},
  url = {http://proceedings.mlr.press/v54/xu17a.html},
  abstract = {The alternating direction method of multi-pliers (ADMM) is a versatile tool for solving a wide range of constrained optimization problems. However, its performance is highly sensitive to a penalty parameter, making ADMM often unreliable and hard to automate for a non-expert user. We tackle this weakness of ADMM by proposing a method that adaptively tunes the penalty parameter to achieve fast convergence. The resulting adaptive ADMM (AADMM) algorithm, inspired by the successful Barzilai-Borwein spectral method for gradient descent, yields fast convergence and relative insensitivity to the initial stepsize and problem scaling.}
}

@article{Xu2017,
  title = {Adaptive {{ADMM}} with {{Spectral Penalty Parameter Selection}}},
  author = {Xu, Zheng and Figueiredo, Mário A.T. T and Goldstein, Tom},
  date = {2017},
  journaltitle = {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, AISTATS 2017},
  publisher = {{PMLR}},
  url = {http://proceedings.mlr.press/v54/xu17a.html},
  abstract = {The alternating direction method of multi-pliers (ADMM) is a versatile tool for solving a wide range of constrained optimization problems. However, its performance is highly sensitive to a penalty parameter, making ADMM often unreliable and hard to automate for a non-expert user. We tackle this weakness of ADMM by proposing a method that adaptively tunes the penalty parameter to achieve fast convergence. The resulting adaptive ADMM (AADMM) algorithm, inspired by the successful Barzilai-Borwein spectral method for gradient descent, yields fast convergence and relative insensitivity to the initial stepsize and problem scaling.}
}

@article{Xu2017a,
  title = {Adaptive {{ADMM}} with {{Spectral Penalty Parameter Selection}}},
  author = {Xu, Zheng and Figueiredo, Mário A.T. T and Goldstein, Tom},
  date = {2017},
  journaltitle = {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, AISTATS 2017},
  publisher = {{PMLR}},
  url = {http://proceedings.mlr.press/v54/xu17a.html},
  abstract = {The alternating direction method of multi-pliers (ADMM) is a versatile tool for solving a wide range of constrained optimization problems. However, its performance is highly sensitive to a penalty parameter, making ADMM often unreliable and hard to automate for a non-expert user. We tackle this weakness of ADMM by proposing a method that adaptively tunes the penalty parameter to achieve fast convergence. The resulting adaptive ADMM (AADMM) algorithm, inspired by the successful Barzilai-Borwein spectral method for gradient descent, yields fast convergence and relative insensitivity to the initial stepsize and problem scaling.}
}

@article{Xua,
  title = {An {{Empirical Study}} of {{ADMM}} for {{Nonconvex Problems}}},
  author = {Xu, Zheng and De, Soham and Figueiredo, Mário A T and Studer, Christoph and Goldstein, Tom},
  abstract = {The alternating direction method of multipliers (ADMM) is a common optimization tool for solving constrained and non-differentiable problems. We provide an empirical study of the practical performance of ADMM on several nonconvex applications, including 0 regularized linear regression, 0 regularized image de-noising, phase retrieval, and eigenvector computation. Our experiments suggest that ADMM performs well on a broad class of non-convex problems. Moreover, recently proposed adaptive ADMM methods, which automatically tune penalty parameters as the method runs, can improve algorithm efficiency and solution quality compared to ADMM with a non-tuned penalty.}
}


